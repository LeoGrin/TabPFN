{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-15T12:35:06.026497450Z",
     "start_time": "2023-04-15T12:35:05.498842446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57580, 54) (57580,)\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "import os\n",
    "import numpy as np\n",
    "# import train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "openml.config.cache_directory = os.path.expanduser('/storage/store/work/lgrinszt/openml_cache')\n",
    "task_id = 361071\n",
    "task = openml.tasks.get_task(task_id)\n",
    "X, y = task.get_X_and_y()\n",
    "print(X.shape, y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Restrict X_train to 1000 samples to speed up the example\n",
    "X_train, y_train = X_train[:1000], y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-04-15T12:35:06.028019400Z",
     "start_time": "2023-04-15T12:35:06.024841265Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-04-15T12:36:23.271193395Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soda/lgrinszt/.local/miniconda3/envs/tab_pfn2/lib/python3.9/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.differentiable_pfn_evaluation import eval_model_range\n",
    "from scripts.model_builder import get_model, get_default_spec, save_model, load_model\n",
    "from scripts.transformer_prediction_interface import transformer_predict, get_params_from_config, load_model_workflow\n",
    "\n",
    "from scripts.model_configs import *\n",
    "\n",
    "from datasets import load_openml_list, open_cc_dids, open_cc_valid_dids\n",
    "from priors.utils import plot_prior, plot_features\n",
    "from priors.utils import uniform_int_sampler_f\n",
    "\n",
    "from scripts.tabular_metrics import calculate_score_per_method, calculate_score\n",
    "from scripts.tabular_evaluation import evaluate\n",
    "\n",
    "from priors.differentiable_prior import DifferentiableHyperparameterList, draw_random_style, merge_style_with_info\n",
    "from scripts import tabular_metrics\n",
    "from notebook_utils import *\n",
    "import argparse\n",
    "import wandb \n",
    "large_datasets = True\n",
    "max_samples = 10000 if large_datasets else 5000\n",
    "bptt = 10000 if large_datasets else 3000\n",
    "suite='cc'\n",
    "base_path = '.'\n",
    "max_features = 100\n",
    "\n",
    "args = argparse.Namespace()\n",
    "args.prior = \"trees\"\n",
    "args.task_type = 'multiclass'\n",
    "args.device = 4\n",
    "args.wandb = False\n",
    "args.name = \"test\"\n",
    "args.save_every = 59\n",
    "\n",
    "device = 'cuda:{}'.format(args.device) if args.device >= 0 else 'cpu'\n",
    "\n",
    "\n",
    "def print_models(model_string):\n",
    "    print(model_string)\n",
    "\n",
    "    for i in range(80):\n",
    "        for e in range(50):\n",
    "            exists = Path(os.path.join(base_path, f'models_diff/prior_diff_real_checkpoint{model_string}_n_{i}_epoch_{e}.cpkt')).is_file()\n",
    "            if exists:\n",
    "                print(os.path.join(base_path, f'models_diff/prior_diff_real_checkpoint{model_string}_n_{i}_epoch_{e}.cpkt'))\n",
    "        print()\n",
    "def train_function(config_sample, i, add_name=''):\n",
    "    start_time = time.time()\n",
    "    N_epochs_to_save = 50\n",
    "    \n",
    "    def save_callback(model, epoch):\n",
    "        if not hasattr(model, 'last_saved_epoch'):\n",
    "            model.last_saved_epoch = 0\n",
    "        if ((time.time() - start_time) / (maximum_runtime * 60 / N_epochs_to_save)) > model.last_saved_epoch:\n",
    "            print('Saving model..')\n",
    "            config_sample['epoch_in_training'] = epoch\n",
    "            save_model(model, base_path, f'models_diff/prior_diff_real_checkpoint{add_name}_n_{i}_epoch_{model.last_saved_epoch}.cpkt',\n",
    "                           config_sample)\n",
    "            model.last_saved_epoch = model.last_saved_epoch + 1 # TODO: Rename to checkpoint\n",
    "    \n",
    "    model = get_model(config_sample\n",
    "                      , device\n",
    "                      , should_train=True\n",
    "                      , verbose=1\n",
    "                      , epoch_callback = save_callback)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def reload_config(config_type='causal', task_type='multiclass', longer=0):\n",
    "    config = get_prior_config(config_type=config_type)\n",
    "    \n",
    "    config['prior_type'], config['differentiable'], config['flexible'] = args.prior, True, True\n",
    "    \n",
    "    model_string = ''\n",
    "    \n",
    "    config['epochs'] = 12000\n",
    "    config['recompute_attn'] = True\n",
    "\n",
    "    config['max_num_classes'] = 10\n",
    "    config['num_classes'] = uniform_int_sampler_f(2, config['max_num_classes'])\n",
    "    config['balanced'] = False\n",
    "    model_string = model_string + '_multiclass'\n",
    "    \n",
    "    model_string = model_string + '_'+datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    \n",
    "    return config, model_string\n",
    "\n",
    "config, model_string = reload_config(longer=1)\n",
    "\n",
    "config['bptt_extra_samples'] = None\n",
    "\n",
    "config[\"sampling\"] = \"mixed\"\n",
    "del config['differentiable_hyperparameters']['sampling']\n",
    "config[\"num_classes\"] = 2\n",
    "\n",
    "if config['prior_type'] == 'trees':\n",
    "    config[\"n_trees\"] = 25\n",
    "    config[\"max_depth\"] = 10\n",
    "    config[\"depth_distribution\"] = \"uniform\"\n",
    "    config[\"split_distribution\"] = \"uniform\"\n",
    "    config[\"split_param\"] = 1\n",
    "elif config['prior_type'] == 'mlp':\n",
    "    config['output_multiclass_ordered_p'] = 0.\n",
    "    del config['differentiable_hyperparameters']['output_multiclass_ordered_p']\n",
    "\n",
    "    config['multiclass_type'] = 'rank'\n",
    "    del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "    config['pre_sample_causes'] = True\n",
    "\n",
    "\n",
    "\n",
    "config['multiclass_loss_type'] = 'nono' # 'compatible'\n",
    "config['normalize_to_ranking'] = False # False\n",
    "\n",
    "config['categorical_feature_p'] = .2 # diff: .0\n",
    "\n",
    "# turn this back on in a random search!?\n",
    "config['nan_prob_no_reason'] = .0\n",
    "config['nan_prob_unknown_reason'] = .0 # diff: .0\n",
    "config['set_value_to_nan'] = .1 # diff: 1.\n",
    "\n",
    "config['normalize_with_sqrt'] = False\n",
    "\n",
    "config['new_mlp_per_example'] = True\n",
    "config['prior_mlp_scale_weights_sqrt'] = True\n",
    "config['batch_size_per_gp_sample'] = None\n",
    "\n",
    "config['normalize_ignore_label_too'] = False\n",
    "\n",
    "config['differentiable_hps_as_style'] = False\n",
    "config['max_eval_pos'] = 1000\n",
    "\n",
    "config['random_feature_rotation'] = True\n",
    "config['rotate_normalized_labels'] = True\n",
    "\n",
    "config[\"mix_activations\"] = False # False heisst eig True\n",
    "\n",
    "config['emsize'] = 512\n",
    "config['nhead'] = config['emsize'] // 128\n",
    "config['bptt'] = 1024+128\n",
    "config['canonical_y_encoder'] = False\n",
    "\n",
    "    \n",
    "config['aggregate_k_gradients'] = 8\n",
    "config['batch_size'] = 8*config['aggregate_k_gradients']\n",
    "config['num_steps'] = 1024//config['aggregate_k_gradients']\n",
    "config['epochs'] = 400\n",
    "config['total_available_time_in_s'] = None #60*60*22 # 22 hours for some safety...\n",
    "\n",
    "config['train_mixed_precision'] = True\n",
    "config['efficient_eval_masking'] = True\n",
    "\n",
    "config[\"use_wandb\"] = args.wandb\n",
    "config[\"name\"] = args.name\n",
    "config[\"save_every\"] = args.save_every\n",
    "\n",
    "if args.wandb == True:\n",
    "    wandb.init(project=\"tabpfn_training\", entity=\"leogrin\")\n",
    "    wandb.config.update(config)\n",
    "\n",
    "config_sample = evaluate_hypers(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def load_model(path, filename, device, config_sample, verbose=0):\n",
    "    # TODO: This function only restores evaluation functionality but training can√§t be continued. It is also not flexible.\n",
    "    # print('Loading....')\n",
    "    model_state = torch.load(\n",
    "        os.path.join(path, filename), map_location='cpu')\n",
    "    if ('differentiable_hyperparameters' in config_sample\n",
    "            and 'prior_mlp_activations' in config_sample['differentiable_hyperparameters']):\n",
    "        config_sample['differentiable_hyperparameters']['prior_mlp_activations']['choice_values_used'] = config_sample[\n",
    "                                                                                                         'differentiable_hyperparameters'][\n",
    "                                                                                                         'prior_mlp_activations'][\n",
    "                                                                                                         'choice_values']\n",
    "        config_sample['differentiable_hyperparameters']['prior_mlp_activations']['choice_values'] = [\n",
    "            torch.nn.Tanh for k in config_sample['differentiable_hyperparameters']['prior_mlp_activations']['choice_values']]\n",
    "\n",
    "    config_sample['categorical_features_sampler'] = lambda: lambda x: ([], [], [])\n",
    "    config_sample['num_features_used_in_training'] = config_sample['num_features_used']\n",
    "    config_sample['num_features_used'] = lambda: config_sample['num_features']\n",
    "    config_sample['num_classes_in_training'] = config_sample['num_classes']\n",
    "    config_sample['num_classes'] = 2\n",
    "    config_sample['batch_size_in_training'] = config_sample['batch_size']\n",
    "    config_sample['batch_size'] = 1\n",
    "    config_sample['bptt_in_training'] = config_sample['bptt']\n",
    "    config_sample['bptt'] = 10\n",
    "    config_sample['bptt_extra_samples_in_training'] = config_sample['bptt_extra_samples']\n",
    "    config_sample['bptt_extra_samples'] = None\n",
    "\n",
    "    #print('Memory', str(get_gpu_memory()))\n",
    "\n",
    "    model = get_model(config_sample, device=device, should_train=False, verbose=verbose)\n",
    "    module_prefix = 'module.'\n",
    "    model_state = {k.replace(module_prefix, ''): v for k, v in model_state.items()}\n",
    "    model[2].load_state_dict(model_state)\n",
    "    model[2].to(device)\n",
    "    model[2].eval()\n",
    "\n",
    "    return model, config_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Batch size: 1\n",
      "Using distributed training: False\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    }
   ],
   "source": [
    "#model_pytorch = load_model(\"tabpfn/model_checkpoints\", \"model_mlp60400_140.pt\", 2, config_sample, 1)[0]\n",
    "model_pytorch = load_model(\"tabpfn/model_checkpoints\", \"model_trees25524_160.pt\", 2, config_sample, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Batch size: 1\n",
      "Using distributed training: False\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    }
   ],
   "source": [
    "from tabpfn.scripts.transformer_prediction_interface import TabPFNClassifier\n",
    "\n",
    "model = TabPFNClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0001,\n",
       " 'dropout': 0.0,\n",
       " 'emsize': 512,\n",
       " 'batch_size': 1,\n",
       " 'nlayers': 12,\n",
       " 'num_features': 100,\n",
       " 'nhead': 4,\n",
       " 'nhid_factor': 2,\n",
       " 'bptt': 10,\n",
       " 'eval_positions': [9],\n",
       " 'seq_len_used': 50,\n",
       " 'sampling': 'mixed',\n",
       " 'epochs': 400,\n",
       " 'num_steps': 8192,\n",
       " 'verbose': False,\n",
       " 'mix_activations': True,\n",
       " 'nan_prob_unknown_reason_reason_prior': 1.0,\n",
       " 'categorical_feature_p': 0.2,\n",
       " 'nan_prob_no_reason': 0.0,\n",
       " 'nan_prob_unknown_reason': 0.0,\n",
       " 'nan_prob_a_reason': 0.0,\n",
       " 'max_num_classes': 10,\n",
       " 'num_classes': 2,\n",
       " 'noise_type': 'Gaussian',\n",
       " 'balanced': False,\n",
       " 'normalize_to_ranking': False,\n",
       " 'set_value_to_nan': 0.1,\n",
       " 'normalize_by_used_features': True,\n",
       " 'num_features_used': <function tabpfn.scripts.model_builder.load_model.<locals>.<lambda>()>,\n",
       " 'num_categorical_features_sampler_a': -1.0,\n",
       " 'differentiable_hyperparameters': {'prior_bag_exp_weights_1': {'distribution': 'uniform',\n",
       "   'min': 1000000.0,\n",
       "   'max': 1000001.0},\n",
       "  'num_layers': {'distribution': 'meta_trunc_norm_log_scaled',\n",
       "   'max_mean': 6,\n",
       "   'min_mean': 1,\n",
       "   'round': True,\n",
       "   'lower_bound': 2},\n",
       "  'prior_mlp_hidden_dim': {'distribution': 'meta_trunc_norm_log_scaled',\n",
       "   'max_mean': 130,\n",
       "   'min_mean': 5,\n",
       "   'round': True,\n",
       "   'lower_bound': 4},\n",
       "  'prior_mlp_dropout_prob': {'distribution': 'meta_beta',\n",
       "   'scale': 0.9,\n",
       "   'min': 0.1,\n",
       "   'max': 5.0},\n",
       "  'noise_std': {'distribution': 'meta_trunc_norm_log_scaled',\n",
       "   'max_mean': 0.3,\n",
       "   'min_mean': 0.0001,\n",
       "   'round': False,\n",
       "   'lower_bound': 0.0},\n",
       "  'init_std': {'distribution': 'meta_trunc_norm_log_scaled',\n",
       "   'max_mean': 10.0,\n",
       "   'min_mean': 0.01,\n",
       "   'round': False,\n",
       "   'lower_bound': 0.0},\n",
       "  'num_causes': {'distribution': 'meta_trunc_norm_log_scaled',\n",
       "   'max_mean': 12,\n",
       "   'min_mean': 1,\n",
       "   'round': True,\n",
       "   'lower_bound': 1},\n",
       "  'is_causal': {'distribution': 'meta_choice', 'choice_values': [True, False]},\n",
       "  'pre_sample_weights': {'distribution': 'meta_choice',\n",
       "   'choice_values': [True, False]},\n",
       "  'y_is_effect': {'distribution': 'meta_choice',\n",
       "   'choice_values': [True, False]},\n",
       "  'prior_mlp_activations': {'distribution': 'meta_choice_mixed',\n",
       "   'choice_values': [torch.nn.modules.activation.Tanh,\n",
       "    torch.nn.modules.activation.Tanh,\n",
       "    torch.nn.modules.activation.Tanh,\n",
       "    torch.nn.modules.activation.Tanh],\n",
       "   'choice_values_used': [\"<class 'torch.nn.modules.activation.Tanh'>\",\n",
       "    \"<class 'torch.nn.modules.linear.Identity'>\",\n",
       "    '<function get_diff_causal.<locals>.<lambda> at 0x7fc575dfb670>',\n",
       "    \"<class 'torch.nn.modules.activation.ELU'>\"]},\n",
       "  'block_wise_dropout': {'distribution': 'meta_choice',\n",
       "   'choice_values': [True, False]},\n",
       "  'sort_features': {'distribution': 'meta_choice',\n",
       "   'choice_values': [True, False]},\n",
       "  'in_clique': {'distribution': 'meta_choice', 'choice_values': [True, False]},\n",
       "  'sampling': {'distribution': 'meta_choice',\n",
       "   'choice_values': ['normal', 'mixed']},\n",
       "  'pre_sample_causes': {'distribution': 'meta_choice',\n",
       "   'choice_values': [True, False]},\n",
       "  'outputscale': {'distribution': 'meta_trunc_norm_log_scaled',\n",
       "   'max_mean': 10.0,\n",
       "   'min_mean': 1e-05,\n",
       "   'round': False,\n",
       "   'lower_bound': 0},\n",
       "  'lengthscale': {'distribution': 'meta_trunc_norm_log_scaled',\n",
       "   'max_mean': 10.0,\n",
       "   'min_mean': 1e-05,\n",
       "   'round': False,\n",
       "   'lower_bound': 0},\n",
       "  'noise': {'distribution': 'meta_choice',\n",
       "   'choice_values': [1e-05, 0.0001, 0.01]},\n",
       "  'multiclass_type': {'distribution': 'meta_choice',\n",
       "   'choice_values': ['value', 'rank']}},\n",
       " 'prior_type': 'prior_bag',\n",
       " 'differentiable': True,\n",
       " 'flexible': True,\n",
       " 'aggregate_k_gradients': 8,\n",
       " 'recompute_attn': True,\n",
       " 'bptt_extra_samples': None,\n",
       " 'dynamic_batch_size': False,\n",
       " 'multiclass_loss_type': 'nono',\n",
       " 'output_multiclass_ordered_p': 0.0,\n",
       " 'normalize_with_sqrt': False,\n",
       " 'new_mlp_per_example': True,\n",
       " 'prior_mlp_scale_weights_sqrt': True,\n",
       " 'batch_size_per_gp_sample': None,\n",
       " 'normalize_ignore_label_too': True,\n",
       " 'differentiable_hps_as_style': False,\n",
       " 'max_eval_pos': 1000,\n",
       " 'random_feature_rotation': True,\n",
       " 'rotate_normalized_labels': True,\n",
       " 'canonical_y_encoder': False,\n",
       " 'total_available_time_in_s': None,\n",
       " 'train_mixed_precision': True,\n",
       " 'efficient_eval_masking': True,\n",
       " 'multiclass_type': 'rank',\n",
       " 'done_part_in_training': 0.8425,\n",
       " 'categorical_features_sampler': <function tabpfn.scripts.model_builder.load_model.<locals>.<lambda>()>,\n",
       " 'num_features_used_in_training': {'uniform_int_sampler_f(3,max_features)': '<function <lambda>.<locals>.<lambda> at 0x7fc575dfb5e0>'},\n",
       " 'num_classes_in_training': '<function <lambda>.<locals>.<lambda> at 0x7fc575dfb550>',\n",
       " 'batch_size_in_training': 8,\n",
       " 'bptt_in_training': 1024,\n",
       " 'bptt_extra_samples_in_training': None,\n",
       " 'name': 'default',\n",
       " 'use_wandb': False,\n",
       " 'save_every': 100}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model = model_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import openml\n",
    "import os\n",
    "import numpy as np\n",
    "# import train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "openml.config.cache_directory = os.path.expanduser('/storage/store/work/lgrinszt/openml_cache')\n",
    "task_id = 361060\n",
    "task = openml.tasks.get_task(task_id)\n",
    "X, y = task.get_X_and_y()\n",
    "print(X.shape, y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Restrict X_train to 1000 samples to speed up the example\n",
    "X_train, y_train = X_train[:1000], y_train[:1000]\n",
    "X_test, y_test = X_test[:5000], y_test[:5000]\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import openml\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "def balance_data(x, y):\n",
    "    rng = np.random.RandomState(0)\n",
    "    print(\"Balancing\")\n",
    "    print(x.shape)\n",
    "    indices = [(y == i) for i in np.unique(y)]\n",
    "    sorted_classes = np.argsort(\n",
    "        list(map(sum, indices)))  # in case there are more than 2 classes, we take the two most numerous\n",
    "\n",
    "    n_samples_min_class = sum(indices[sorted_classes[-2]])\n",
    "    print(\"n_samples_min_class\", n_samples_min_class)\n",
    "    indices_max_class = rng.choice(np.where(indices[sorted_classes[-1]])[0], n_samples_min_class, replace=False)\n",
    "    indices_min_class = np.where(indices[sorted_classes[-2]])[0]\n",
    "    total_indices = np.concatenate((indices_max_class, indices_min_class))\n",
    "    y = y[total_indices]\n",
    "    indices_first_class = (y == sorted_classes[-1])\n",
    "    indices_second_class = (y == sorted_classes[-2])\n",
    "    y[indices_first_class] = 0\n",
    "    y[indices_second_class] = 1\n",
    "\n",
    "    return x.iloc[total_indices], y\n",
    "def import_open_ml_data(dataset_id=None, task_id=None, remove_nans=None, impute_nans=None, categorical=False, regression=False, balance=False, rng=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Import data from openML\n",
    "    :param int openml_task_id:\n",
    "    :param path_to_file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if task_id is not None:\n",
    "        task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "        dataset = task.get_dataset()\n",
    "    elif dataset_id is not None:\n",
    "        dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    # retrieve categorical data for encoding\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        dataset_format=\"dataframe\", target=dataset.default_target_attribute\n",
    "    )\n",
    "    categorical_indicator = np.array(categorical_indicator)\n",
    "    print(\"{} categorical columns\".format(sum(categorical_indicator)))\n",
    "    print(\"{} columns\".format(X.shape[1]))\n",
    "    y_encoder = LabelEncoder()\n",
    "\n",
    "    # Replace categorical values by integers for each categorical column\n",
    "    for i, categorical in enumerate(categorical_indicator):\n",
    "        X.iloc[:, i] = X.iloc[:, i].astype('category')\n",
    "        X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
    "        X.iloc[:, i] = X.iloc[:, i].astype('int64')\n",
    "\n",
    "    # remove missing values\n",
    "    assert remove_nans or impute_nans, \"You need to remove or impute nans\"\n",
    "    if remove_nans:\n",
    "        missing_rows_mask = X.isnull().any(axis=1)\n",
    "        if sum(missing_rows_mask) > X.shape[0] / 5:\n",
    "            print(\"Removed {} rows with missing values on {} rows\".format(\n",
    "                sum(missing_rows_mask), X.shape[0]))\n",
    "        X = X[~missing_rows_mask]\n",
    "        y = y[~missing_rows_mask]\n",
    "        n_rows_non_missing = X.shape[0]\n",
    "        if n_rows_non_missing == 0:\n",
    "            print(\"Removed all rows\")\n",
    "            return None\n",
    "    elif impute_nans:\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        # Impute numerical columns with mean and categorical columns with most frequent\n",
    "        categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "        numerical_imputer = SimpleImputer(strategy=\"mean\")\n",
    "        # check that there a > 0 categorical columns\n",
    "        if sum(categorical_indicator) > 0:\n",
    "            X.iloc[:, categorical_indicator] = categorical_imputer.fit_transform(X.iloc[:, categorical_indicator])\n",
    "        # check that there a > 0 numerical columns\n",
    "        if sum(~categorical_indicator) > 0:\n",
    "            X.iloc[:, ~categorical_indicator] = numerical_imputer.fit_transform(X.iloc[:, ~categorical_indicator])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(\"removing {} categorical features among {} features\".format(sum(categorical_indicator), X.shape[1]))\n",
    "    # X = X.to_numpy()[:, ~categorical_indicator]  # remove all categorical columns\n",
    "    # if X.shape[1] == 0:\n",
    "    #     print(\"removed all features, skipping this task\")\n",
    "    #     return None\n",
    "\n",
    "    y = y_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "\n",
    "    if regression:\n",
    "        y = y.astype(np.float64)\n",
    "    else:\n",
    "        y = y.astype(np.int64)\n",
    "\n",
    "    if balance:\n",
    "        X, y = balance_data(X, y)\n",
    "\n",
    "    X = X.to_numpy()\n",
    "\n",
    "    if categorical:\n",
    "        return X, y, categorical_indicator\n",
    "\n",
    "    return X, y, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, _ = import_open_ml_data(task_id=361060, remove_nans=True, impute_nans=False, categorical=False, regression=False, balance=True, rng=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Restrict to 1000 samples for faster training\n",
    "X_train, y_train = X_train[:1000], y_train[:1000]\n",
    "X_test, y_test = X_test[:5000], y_test[:5000]\n",
    "\n",
    "# Train a classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Score the classifier\n",
    "print(\"Accuracy score Random Forest: {}\".format(clf.score(X_test, y_test)))\n",
    "\n",
    "# Train a classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Score the classifier\n",
    "print(\"Accuracy score Gradient Boosting: {}\".format(clf.score(X_test, y_test)))\n",
    "\n",
    "# TabPFN\n",
    "from tabpfn.scripts.transformer_prediction_interface import TabPFNClassifier\n",
    "\n",
    "model = TabPFNClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Score the classifier\n",
    "print(\"Accuracy score TabPFN: {}\".format(model.score(X_test, y_test)))\n",
    "\n",
    "# Replace model in TabPFN\n",
    "model_pytorch = load_model(\"tabpfn/model_checkpoints\", \"model_trees25524_160.pt\", 2, config_sample, 1)[0]\n",
    "model.model = model_pytorch\n",
    "\n",
    "# Fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Score the classifier\n",
    "print(\"Accuracy score TabPFN trees: {}\".format(model.score(X_test, y_test)))\n",
    "\n",
    "# Replace model in TabPFN\n",
    "\n",
    "\n",
    "model_pytorch = load_model(\"tabpfn/model_checkpoints\", \"model_mlp60400_160.pt\", 2, config_sample, 1)[0]\n",
    "\n",
    "model.model = model_pytorch\n",
    "\n",
    "# Fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Score the classifier\n",
    "print(\"Accuracy score TabPFN MLP: {}\".format(model.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "\n",
    "model_pytorch = load_model(\"tabpfn/model_checkpoints\", \"model_trees33888_8.pt\", 2, config_sample, 1)[0]\n",
    "\n",
    "model.model = model_pytorch\n",
    "\n",
    "# Fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Score the classifier\n",
    "print(\"Accuracy score TabPFN Trees 2: {}\".format(model.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same thing for all tasks in openml suite 2\n",
    "# and put everything in a pd dataframe\n",
    "import pandas as pd\n",
    "suite = openml.study.get_suite(337)\n",
    "tasks = suite.tasks\n",
    "\n",
    "n_repeat = 3\n",
    "\n",
    "results = pd.DataFrame(columns=[\"task_id\", \"accuracy\", \"model\"])\n",
    "for task_id in tasks:\n",
    "    print(\"Task id: {}\".format(task_id))\n",
    "    X, y, _ = import_open_ml_data(task_id=task_id, remove_nans=True, impute_nans=False, categorical=False, regression=False, balance=True, rng=None)\n",
    "    if X.shape[1] > 100:\n",
    "        print(\"skipping task {} because it has too many features\".format(task_id))\n",
    "        continue\n",
    "    if X is None:\n",
    "        print(\"skipping task {} because it has no features\".format(task_id))\n",
    "        continue\n",
    "\n",
    "    # Evaluate the models n_repeat times\n",
    "\n",
    "    for i in range(n_repeat):\n",
    "        # Split the data into a training set and a test set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "\n",
    "        # Restrict to 1000 samples for faster training\n",
    "        X_train, y_train = X_train[:1000], y_train[:1000]\n",
    "        X_test, y_test = X_test[:5000], y_test[:5000]\n",
    "\n",
    "        # Train a classifier\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Score the classifier\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
    "\n",
    "        # Train a classifier\n",
    "        clf = GradientBoostingClassifier()\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Score the classifier\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n",
    "\n",
    "        # TabPFN\n",
    "        model = TabPFNClassifier(N_ensemble_configurations=1)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Score the classifier\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n",
    "\n",
    "        # TabPFN\n",
    "        model = TabPFNClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Score the classifier\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n",
    "\n",
    "        # Replace model in TabPFN\n",
    "        model_pytorch = load_model(\"tabpfn/model_checkpoints\", \"model_trees13368_60.pt\", 2, config_sample, 1)[0]\n",
    "        model.model = model_pytorch\n",
    "\n",
    "        # Fit\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Score the classifier\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n",
    "\n",
    "\n",
    "        # Replace model in TabPFN\n",
    "        model_pytorch = load_model(\"tabpfn/model_checkpoints\", \"model_trees456_45.pt\", 2, config_sample, 1)[0]\n",
    "        model.model = model_pytorch\n",
    "\n",
    "        # Fit\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Score the classifier\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        # # Replace model in TabPFN\n",
    "        # model_pytorch = load_model(\"tabpfn/model_checkpoints\", \"model_trees60473_75.pt\", 2, config_sample, 1)[0]\n",
    "        # model.model = model_pytorch\n",
    "\n",
    "        # # Fit\n",
    "        # model.fit(X_train, y_train)\n",
    "\n",
    "        # # Score the classifier\n",
    "        # accuracy = model.score(X_test, y_test)\n",
    "        # results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 75\"}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        # # Replace model in TabPFN\n",
    "        # model_pytorch = load_model(\"tabpfn/model_checkpoints\", \"model_trees89438_60.pt\", 2, config_sample, 1)[0]\n",
    "        # model.model = model_pytorch\n",
    "\n",
    "        # # Fit\n",
    "        # model.fit(X_train, y_train)\n",
    "\n",
    "        # # Score the classifier\n",
    "        # accuracy = model.score(X_test, y_test)\n",
    "        # results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
    "\n",
    "        # # Replace model in TabPFN\n",
    "        # model_pytorch = load_model(\"tabpfn/model_checkpoints\", \"model_trees89438_45.pt\", 2, config_sample, 1)[0]\n",
    "        # model.model = model_pytorch\n",
    "\n",
    "        # # Fit\n",
    "        # model.fit(X_train, y_train)\n",
    "\n",
    "        # # Score the classifier\n",
    "        # accuracy = model.score(X_test, y_test)\n",
    "        # results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 1\"}, ignore_index=True)\n",
    "\n",
    "        # # Replace model in TabPFN\n",
    "        # model_pytorch = load_model(\"tabpfn/model_checkpoints\", \"model_mlp71353_400.pt\", 2, config_sample, 1)[0]\n",
    "        # model.model = model_pytorch\n",
    "\n",
    "        # # Fit\n",
    "        # model.fit(X_train, y_train)\n",
    "\n",
    "        # # Score the classifier\n",
    "        # accuracy = model.score(X_test, y_test)\n",
    "        # results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN MLP\"}, ignore_index=True)\n",
    "\n",
    "results.to_csv(\"results.csv\")    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose tasks with less than 100 features\n",
    "accepted_tasks = []\n",
    "for task_id in tasks:\n",
    "    print(\"Task id: {}\".format(task_id))\n",
    "    X, y, _ = import_open_ml_data(task_id=task_id, remove_nans=True, impute_nans=False, categorical=False, regression=False, balance=True, rng=None)\n",
    "    if X.shape[1] > 100:\n",
    "        print(\"skipping task {} because it has too many features\".format(task_id))\n",
    "        continue\n",
    "    if X is None:\n",
    "        print(\"skipping task {} because it has no features\".format(task_id))\n",
    "        continue\n",
    "    accepted_tasks.append(task_id)\n",
    "\n",
    "results = results[results[\"task_id\"].isin(accepted_tasks)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "# Convert tasks to string\n",
    "results[\"task_id\"] = results[\"task_id\"].astype(str)\n",
    "# scatter plot with jitter\n",
    "sns.stripplot(x=\"task_id\", y=\"accuracy\", hue=\"model\", data=results, jitter=0.05, dodge=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute how results change for different checkpoints\n",
    "# and put everything in a pd dataframe\n",
    "import pandas as pd\n",
    "suite = openml.study.get_suite(337)\n",
    "tasks = suite.tasks\n",
    "\n",
    "n_repeat = 3\n",
    "\n",
    "results = pd.DataFrame(columns=[\"task_id\", \"accuracy\", \"model\", \"checkpoint\"])\n",
    "for task_id in tasks:\n",
    "    print(\"Task id: {}\".format(task_id))\n",
    "    X, y, _ = import_open_ml_data(task_id=task_id, remove_nans=True, impute_nans=False, categorical=False, regression=False, balance=True, rng=None)\n",
    "    if X.shape[1] > 100:\n",
    "        print(\"skipping task {} because it has too many features\".format(task_id))\n",
    "        continue\n",
    "    if X is None:\n",
    "        print(\"skipping task {} because it has no features\".format(task_id))\n",
    "        continue\n",
    "\n",
    "    # Evaluate the models n_repeat times\n",
    "\n",
    "    for i in range(n_repeat):\n",
    "        # Split the data into a training set and a test set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "\n",
    "        # Restrict to 1000 samples for faster training\n",
    "        X_train, y_train = X_train[:1000], y_train[:1000]\n",
    "        X_test, y_test = X_test[:5000], y_test[:5000]\n",
    "\n",
    "        # TabPFN\n",
    "        model = TabPFNClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Score the classifier\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\", \"checkpoint\": np.nan}, ignore_index=True)\n",
    "\n",
    "        for checkpoint in range(10, 400, 50):\n",
    "            # Replace model in TabPFN\n",
    "            model_pytorch = load_model(\"tabpfn/model_checkpoints\", \"model_mlp71353_{}.pt\".format(checkpoint), 2, config_sample, 1)[0]\n",
    "            model.model = model_pytorch\n",
    "\n",
    "            # Fit\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Score the classifier\n",
    "            accuracy = model.score(X_test, y_test)\n",
    "            results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN MLP\", \"checkpoint\": checkpoint}, ignore_index=True)\n",
    "        \n",
    "        # Use Gradient Boosting as a baseline\n",
    "        clf = GradientBoostingClassifier()\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Score the classifier\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\", \"checkpoint\": np.nan}, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "# Convert tasks to string\n",
    "results[\"task_id\"] = results[\"task_id\"].astype(str)\n",
    "# scatter plot with jitter\n",
    "# Plot a different color for each checkpoint\n",
    "ax = sns.stripplot(x=\"task_id\", y=\"accuracy\", hue=\"checkpoint\", data=results, jitter=0.05, dodge=True)\n",
    "# Plot the model without checkpoint\n",
    "#ax2 = sns.stripplot(x=\"task_id\", y=\"accuracy\", hue=\"model\", data=results[results[\"checkpoint\"].isna()], jitter=0.05, dodge=True)\n",
    "#ax = sns.stripplot(x=\"task_id\", y=\"accuracy\", hue=\"model\", data=results, jitter=0.05, dodge=True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results  for all  tasks and models in results.csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "results = pd.read_csv(\"results.csv\")\n",
    "results = results.drop(columns=[\"Unnamed: 0\"])\n",
    "results = results[results[\"accuracy\"] < 1.0]\n",
    "results = results[results[\"accuracy\"] > 0.0]\n",
    "\n",
    "# Plot the results for each task\n",
    "# for task_id in results[\"task_id\"].unique():\n",
    "#     print(\"Task id: {}\".format(task_id))\n",
    "#     results_task = results[results[\"task_id\"] == task_id]\n",
    "#     ax = sns.boxplot(x=\"model\", y=\"accuracy\", data=results_task)\n",
    "#     ax.set_title(\"Task id: {}\".format(task_id))\n",
    "#     plt.show()\n",
    "# Replace by one scatterplot\n",
    "ax = sns.scatterplot(x=\"model\", y=\"accuracy\", hue=\"task_id\", data=results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task id: 361110\n",
      "1 categorical columns\n",
      "8 columns\n",
      "Balancing\n",
      "(38474, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:47: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].astype('category')\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples_min_class 19237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task id: 361111\n",
      "3 categorical columns\n",
      "23 columns\n",
      "Balancing\n",
      "(7608, 23)\n",
      "n_samples_min_class 3804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:47: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].astype('category')\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:47: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].astype('category')\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task id: 361113\n",
      "44 categorical columns\n",
      "54 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:47: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].astype('category')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing\n",
      "(423680, 54)\n",
      "n_samples_min_class 211840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task id: 361282\n",
      "10 categorical columns\n",
      "31 columns\n",
      "Balancing\n",
      "(58252, 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:47: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].astype('category')\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:47: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].astype('category')\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:47: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].astype('category')\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:47: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].astype('category')\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples_min_class 29126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task id: 361283\n",
      "1 categorical columns\n",
      "21 columns\n",
      "Balancing\n",
      "(13272, 21)\n",
      "n_samples_min_class 6636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:47: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].astype('category')\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task id: 361285\n",
      "3 categorical columns\n",
      "32 columns\n",
      "Balancing\n",
      "(111762, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:47: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].astype('category')\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:47: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].astype('category')\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:47: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].astype('category')\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples_min_class 55881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task id: 361286\n",
      "8 categorical columns\n",
      "11 columns\n",
      "Balancing\n",
      "(4966, 11)\n",
      "n_samples_min_class 2483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/406963134.py:47: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].astype('category')\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:48: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].cat.codes\n",
      "/tmp/ipykernel_6963/406963134.py:47: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X.iloc[:, i] = X.iloc[:, i].astype('category')\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
      "/tmp/ipykernel_6963/1826081905.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using cpu device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' (namespace)>\n",
      "Using 2 device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6963/1826081905.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Do the same thing for all tasks in openml suite 2\n",
    "# and put everything in a pd dataframe\n",
    "import pandas as pd\n",
    "suite = openml.study.get_suite(334) # categorical classification\n",
    "tasks = suite.tasks\n",
    "\n",
    "n_repeat = 3\n",
    "\n",
    "results = pd.DataFrame(columns=[\"task_id\", \"accuracy\", \"model\"])\n",
    "for task_id in tasks:\n",
    "    print(\"Task id: {}\".format(task_id))\n",
    "    X, y, _ = import_open_ml_data(task_id=task_id, remove_nans=True, impute_nans=False, categorical=True, regression=False, balance=True, rng=None)\n",
    "    if X.shape[1] > 100:\n",
    "        print(\"skipping task {} because it has too many features\".format(task_id))\n",
    "        continue\n",
    "    if X is None:\n",
    "        print(\"skipping task {} because it has no features\".format(task_id))\n",
    "        continue\n",
    "\n",
    "    # Evaluate the models n_repeat times\n",
    "\n",
    "    for i in range(n_repeat):\n",
    "        # Split the data into a training set and a test set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "\n",
    "        # Restrict to 1000 samples for faster training\n",
    "        X_train, y_train = X_train[:1000], y_train[:1000]\n",
    "        X_test, y_test = X_test[:5000], y_test[:5000]\n",
    "\n",
    "        # Train a classifier\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Score the classifier\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Random Forest\"}, ignore_index=True)\n",
    "\n",
    "        # Train a classifier\n",
    "        clf = GradientBoostingClassifier()\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Score the classifier\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"Gradient Boosting\"}, ignore_index=True)\n",
    "\n",
    "        # TabPFN\n",
    "        model = TabPFNClassifier(N_ensemble_configurations=1)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Score the classifier\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFNne\"}, ignore_index=True)\n",
    "\n",
    "        # TabPFN\n",
    "        model = TabPFNClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Score the classifier\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN\"}, ignore_index=True)\n",
    "        # Replace model in TabPFN\n",
    "        model_pytorch = load_model(\"tabpfn/model_checkpoints\", \"model_trees13368_60.pt\", 2, config_sample, 1)[0]\n",
    "        model.model = model_pytorch\n",
    "\n",
    "        # Fit\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Score the classifier\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees\"}, ignore_index=True)\n",
    "\n",
    "\n",
    "        # Replace model in TabPFN\n",
    "        model_pytorch = load_model(\"tabpfn/model_checkpoints\", \"model_trees456_45.pt\", 2, config_sample, 1)[0]\n",
    "        model.model = model_pytorch\n",
    "\n",
    "        # Fit\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Score the classifier\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        results = results.append({\"task_id\": task_id, \"accuracy\": accuracy, \"model\": \"TabPFN trees 2\"}, ignore_index=True)\n",
    "\n",
    "results.to_csv(\"results_categorical.csv\")    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>361110</td>\n",
       "      <td>0.786600</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>361110</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>361110</td>\n",
       "      <td>0.779000</td>\n",
       "      <td>TabPFNne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>361110</td>\n",
       "      <td>0.776800</td>\n",
       "      <td>TabPFN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>361110</td>\n",
       "      <td>0.769400</td>\n",
       "      <td>TabPFN trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>361286</td>\n",
       "      <td>0.635815</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>361286</td>\n",
       "      <td>0.677062</td>\n",
       "      <td>TabPFNne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>361286</td>\n",
       "      <td>0.678068</td>\n",
       "      <td>TabPFN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>361286</td>\n",
       "      <td>0.660966</td>\n",
       "      <td>TabPFN trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>361286</td>\n",
       "      <td>0.667002</td>\n",
       "      <td>TabPFN trees 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    task_id  accuracy              model\n",
       "0    361110  0.786600      Random Forest\n",
       "1    361110  0.782000  Gradient Boosting\n",
       "2    361110  0.779000           TabPFNne\n",
       "3    361110  0.776800             TabPFN\n",
       "4    361110  0.769400       TabPFN trees\n",
       "..      ...       ...                ...\n",
       "121  361286  0.635815  Gradient Boosting\n",
       "122  361286  0.677062           TabPFNne\n",
       "123  361286  0.678068             TabPFN\n",
       "124  361286  0.660966       TabPFN trees\n",
       "125  361286  0.667002     TabPFN trees 2\n",
       "\n",
       "[126 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose tasks with less than 100 features\n",
    "accepted_tasks = []\n",
    "for task_id in tasks:\n",
    "    print(\"Task id: {}\".format(task_id))\n",
    "    X, y, _ = import_open_ml_data(task_id=task_id, remove_nans=True, impute_nans=False, categorical=True, regression=False, balance=True, rng=None)\n",
    "    if X.shape[1] > 100:\n",
    "        print(\"skipping task {} because it has too many features\".format(task_id))\n",
    "        continue\n",
    "    if X is None:\n",
    "        print(\"skipping task {} because it has no features\".format(task_id))\n",
    "        continue\n",
    "    accepted_tasks.append(task_id)\n",
    "\n",
    "results = results[results[\"task_id\"].isin(accepted_tasks)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "# Convert tasks to string\n",
    "results[\"task_id\"] = results[\"task_id\"].astype(str)\n",
    "# scatter plot with jitter\n",
    "sns.stripplot(x=\"task_id\", y=\"accuracy\", hue=\"model\", data=results, jitter=0.05, dodge=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tab_pfn2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21dbb7094b1385f0bae0b91ae49063169e8dea4181459eda714e1f1fb7500475"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
