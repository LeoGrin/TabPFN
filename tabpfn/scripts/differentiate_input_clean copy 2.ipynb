{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' from '/home/parietal/lgrinszt/.local/miniconda3/envs/tab_pfn2/lib/python3.9/site-packages/wandb/__init__.py'>\n",
      "Using cuda:2 device\n",
      "Batch size: 1\n",
      "Using distributed training: False\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    }
   ],
   "source": [
    "from tabpfn.scripts.transformer_prediction_interface import TabPFNClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, PowerTransformer, RobustScaler\n",
    "import torch\n",
    "from torch.nn import MultiheadAttention\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "\n",
    "device = \"cuda:2\"\n",
    "\n",
    "model = TabPFNClassifier(device=device)\n",
    "module = model.model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn.utils import normalize_data, to_ranking_low_mem, remove_outliers\n",
    "from tabpfn.priors.utils import normalize_by_used_features_f\n",
    "\n",
    "normalize_with_test = True #TODO change\n",
    "#eval_position = 100\n",
    "normalize_to_ranking = False\n",
    "max_features=100\n",
    "normalize_with_sqrt = False\n",
    "\n",
    "def preprocess_input(eval_xs, eval_ys, categorical_feats, preprocess_transform):\n",
    "    import warnings\n",
    "\n",
    "    if eval_xs.shape[1] > 1:\n",
    "        raise Exception(\"Transforms only allow one batch dim - TODO\")\n",
    "    if preprocess_transform != 'none':\n",
    "        if preprocess_transform == 'power' or preprocess_transform == 'power_all':\n",
    "            pt = PowerTransformer(standardize=True)\n",
    "        elif preprocess_transform == 'quantile' or preprocess_transform == 'quantile_all':\n",
    "            pt = QuantileTransformer(output_distribution='normal')\n",
    "        elif preprocess_transform == 'robust' or preprocess_transform == 'robust_all':\n",
    "            pt = RobustScaler(unit_variance=True)\n",
    "\n",
    "    # eval_xs, eval_ys = normalize_data(eval_xs), normalize_data(eval_ys)\n",
    "    eval_xs = normalize_data(eval_xs, normalize_positions=-1 if normalize_with_test else eval_position)\n",
    "\n",
    "    # Removing empty features\n",
    "    eval_xs = eval_xs[:, 0, :]\n",
    "    sel = [len(torch.unique(eval_xs[0:eval_ys.shape[0], col])) > 1 for col in range(eval_xs.shape[1])]\n",
    "    eval_xs = eval_xs[:, sel]\n",
    "\n",
    "    warnings.simplefilter('error')\n",
    "    if preprocess_transform != 'none':\n",
    "        eval_xs = eval_xs.cpu().numpy()\n",
    "        feats = set(range(eval_xs.shape[1])) if 'all' in preprocess_transform else set(\n",
    "            range(eval_xs.shape[1])) - set(categorical_feats)\n",
    "        for col in feats:\n",
    "            try:\n",
    "                pt.fit(eval_xs[0:eval_position, col:col + 1])\n",
    "                trans = pt.transform(eval_xs[:, col:col + 1])\n",
    "                # print(scipy.stats.spearmanr(trans[~np.isnan(eval_xs[:, col:col+1])], eval_xs[:, col:col+1][~np.isnan(eval_xs[:, col:col+1])]))\n",
    "                eval_xs[:, col:col + 1] = trans\n",
    "            except:\n",
    "                pass\n",
    "        eval_xs = torch.tensor(eval_xs).float()\n",
    "    warnings.simplefilter('default')\n",
    "\n",
    "    eval_xs = eval_xs.unsqueeze(1)\n",
    "\n",
    "    # TODO: Cautian there is information leakage when to_ranking is used, we should not use it\n",
    "    eval_xs = remove_outliers(eval_xs, normalize_positions=-1 if normalize_with_test else eval_position) if not normalize_to_ranking else normalize_data(to_ranking_low_mem(eval_xs))\n",
    "    # Rescale X\n",
    "    eval_xs = normalize_by_used_features_f(eval_xs, eval_xs.shape[-1], max_features,\n",
    "                                            normalize_with_sqrt=normalize_with_sqrt)\n",
    "\n",
    "    return eval_xs.detach().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_rf(X, y, n_train):\n",
    "    # Move X and y to CPU\n",
    "    X = X.to(\"cpu\")\n",
    "    y = y.to(\"cpu\")\n",
    "    # check if regression or classification\n",
    "    if len(np.unique(y)) > len(y) / 3:\n",
    "        rf = RandomForestRegressor()\n",
    "        classif = False\n",
    "        print(\"Regression\")\n",
    "    else:\n",
    "        rf = RandomForestClassifier()\n",
    "        classif = True\n",
    "        print(\"Classification\")\n",
    "    X_train, X_test = X[:n_train], X[n_train:]\n",
    "    y_train, y_test = y[:n_train], y[n_train:]\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    if classif:\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "    else:\n",
    "        # mean absolute error\n",
    "        return mean_squared_error(y_test, y_pred)\n",
    "\n",
    "def compute_accuracy_tabpfn_original(X, y, n_train):\n",
    "    X = X.to(\"cpu\") #FIXME\n",
    "    y = y.to(\"cpu\")\n",
    "    X_train, X_test = X[:n_train], X[n_train:]\n",
    "    y_train, y_test = y[:n_train], y[n_train:]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def compute_accuracy_tabpfn(X, y, n_train, preprocess=False):\n",
    "    # reshape X to be 3D\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    # reshape y to be 2D\n",
    "    y = y.reshape(y.shape[0], 1)\n",
    "    if preprocess:\n",
    "        X = preprocess_input(X, y, [], 'power')\n",
    "    X = X.to(device)\n",
    "    y_pred = torch.argmax(module((X, y), single_eval_pos=n_train, x_already_encoded=False), dim=-1).reshape(-1)\n",
    "    # Check the accuracy\n",
    "    print(accuracy_score(y[-len(y_pred):].cpu(), y_pred.cpu())) #FIXME\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 192])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# class PairwiseTransformer(nn.Module):\n",
    "#     def __init__(self, n_features, n_features_2, nhead, dim_feedforward):\n",
    "#         super(PairwiseTransformer, self).__init__()\n",
    "#         self.transformer = nn.Transformer(\n",
    "#             d_model=n_features + n_features_2,\n",
    "#             nhead=nhead,\n",
    "#             num_encoder_layers=1,\n",
    "#             num_decoder_layers=1,\n",
    "#             dim_feedforward=dim_feedforward,\n",
    "#         )\n",
    "#         self.fc = nn.Linear(n_features + n_features_2, 1)\n",
    "\n",
    "#     def forward(self, x1, x2):\n",
    "#         print(x1.shape)\n",
    "#         print(x2.shape)\n",
    "#         combined_input = torch.cat((x1, x2), dim=-1).unsqueeze(0)\n",
    "#         print(combined_input.shape)\n",
    "#         output = self.transformer(combined_input, combined_input)\n",
    "#         output = output.squeeze(0)\n",
    "#         score = self.fc(output)\n",
    "#         return score.squeeze(-1)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, classif=True):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.classif = classif\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        if self.classif:\n",
    "            out = F.softmax(out, dim=-1)\n",
    "        return out\n",
    "\n",
    "class PairwiseMLP(nn.Module):\n",
    "    def __init__(self, n_features, n_features_2, dim_feedforward):\n",
    "        super(PairwiseMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features + n_features_2, dim_feedforward)\n",
    "        self.fc2 = nn.Linear(dim_feedforward, dim_feedforward)\n",
    "        self.fc3 = nn.Linear(dim_feedforward, 1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        combined_input = torch.cat((x1, x2), dim=-1)\n",
    "        output = F.relu(self.fc1(combined_input))\n",
    "        output = F.relu(self.fc2(output))\n",
    "        score = self.fc3(output)\n",
    "        return score.squeeze(-1)\n",
    "    \n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, n_features, n_features_2, dim_feedforward):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.scorer = PairwiseMLP(n_features, n_features_2, dim_feedforward)\n",
    "\n",
    "    def forward(self, M1, M2):\n",
    "        scores = []\n",
    "        for i in range(M1.size(0)):\n",
    "                score = self.scorer(M1[i].repeat(M2.shape[0], 1), M2)\n",
    "                scores.append(score)\n",
    "        scores = torch.stack(scores).view(M1.size(0), M2.size(0))\n",
    "        # Normalize scores\n",
    "        scores = F.softmax(scores, dim=1)\n",
    "        M2_avg = scores @ M2\n",
    "        return torch.cat((M1, M2_avg), dim=1)\n",
    "\n",
    "# Example usage\n",
    "n_samples_batch, n_features = 32, 128\n",
    "n_samples_2, n_features_2 = 16, 64\n",
    "nhead = 8\n",
    "dim_feedforward = 256\n",
    "\n",
    "matching_model = CustomModel(n_features, n_features_2, dim_feedforward)\n",
    "\n",
    "M1 = torch.randn(n_samples_batch, n_features)\n",
    "M2 = torch.randn(n_samples_2, n_features_2)\n",
    "\n",
    "output = matching_model(M1, M2)\n",
    "print(output.shape)  # Expected output shape: (n_samples_batch, n_features + n_features_2)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_matching(X1, X2, y, batch_size, scorer, preprocess=False, lr=0.01, n_epochs=100, dim_feedforward=256, train_prop=0.7, n_train=None, ):\n",
    "    # reshape X to be 3D\n",
    "    X1 = X1.reshape(X1.shape[0], 1, X1.shape[1])\n",
    "    X2 = X2.reshape(X2.shape[0], 1, X2.shape[1])\n",
    "    # reshape y to be 2D\n",
    "    y = y.reshape(y.shape[0], 1)\n",
    "    # check if classification or regression\n",
    "    if len(torch.unique(y)) > len(y) / 3:\n",
    "        classif = False\n",
    "        print(\"regression\")\n",
    "    else:\n",
    "        classif = True\n",
    "        print(\"classification\")\n",
    "    if preprocess:\n",
    "        X1 = preprocess_input(X1, y, [], 'power')\n",
    "        X2 = preprocess_input(X2, y, [], 'power')\n",
    "    # reshape X to be 2D\n",
    "    X1 = X1.reshape(X1.shape[0], X1.shape[2])\n",
    "    X2 = X2.reshape(X2.shape[0], X2.shape[2]).to(device)\n",
    "    # reshape y to be 1D\n",
    "    y = y.reshape(y.shape[0])\n",
    "    if classif:\n",
    "        n_classes = torch.unique(y).shape[0]\n",
    "        print(\"num classes\", n_classes)\n",
    "        predictor = MLP(input_size=X1.shape[1] + X2.shape[1], hidden_size=dim_feedforward, output_size=n_classes, classif=True)\n",
    "    else:\n",
    "        predictor = MLP(input_size=X1.shape[1] + X2.shape[1], hidden_size=dim_feedforward, output_size=1, classif=False)\n",
    "\n",
    "    # move to GPU\n",
    "    scorer = scorer.to(device)\n",
    "    predictor = predictor.to(device)\n",
    "    optimizer = optim.Adam([*scorer.parameters(), *predictor.parameters()], lr=lr)\n",
    "    # create a dataset\n",
    "    print(X1.shape)\n",
    "    print(y.shape)\n",
    "    assert train_prop is not None or n_train is not None\n",
    "    assert train_prop is None or n_train is None\n",
    "    if n_train is not None:\n",
    "        X1_train = X1[:n_train]\n",
    "        y_train = y[:n_train]\n",
    "        X1_test = X1[n_train:]\n",
    "        y_test = y[n_train:]\n",
    "    else:\n",
    "        X1_train = X1[:int(train_prop * len(X1))]\n",
    "        X1_test = X1[int(train_prop * len(X1)):]\n",
    "        y_train = y[:int(train_prop * len(y))]\n",
    "        y_test = y[int(train_prop * len(y)):]\n",
    "    dataset_train = torch.utils.data.TensorDataset(X1_train, y_train)\n",
    "    dataset_test = torch.utils.data.TensorDataset(X1_test, y_test)\n",
    "    # create a data loader\n",
    "    dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "    if classif:\n",
    "        loss_function = torch.nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        loss_function = torch.nn.MSELoss()\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0\n",
    "        train_score = 0\n",
    "        for X1_batch, y_batch in dataloader_train:\n",
    "            # move to GPU\n",
    "            X1_batch = X1_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            # get the predictions\n",
    "            output = scorer(X1_batch, X2)\n",
    "            output = predictor(output).reshape(-1)\n",
    "            # calculate the loss\n",
    "            loss = loss_function(output, y_batch)\n",
    "            train_loss += loss.data.item()\n",
    "            if classif:\n",
    "                score = (output.argmax(dim=1) == y_batch).float().mean()\n",
    "            else:\n",
    "                score = mean_squared_error(output.detach().cpu(), y_batch.cpu())\n",
    "            train_score += score\n",
    "            #print(\"Train loss\", loss.item())\n",
    "            # backprop\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch\", epoch)\n",
    "            print(\"----------------\")\n",
    "            print(\"Train loss\", train_loss / len(dataloader_train))\n",
    "            print(\"Train score\", train_score / len(dataloader_train))\n",
    "            # calculate the accuracy\n",
    "            print(\"---------------\")\n",
    "            test_loss = 0\n",
    "            test_accuracy = 0\n",
    "            for X1_batch, y_batch in dataloader_test:\n",
    "                # move to GPU\n",
    "                X1_batch = X1_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                # Calculate the predictions\n",
    "                output = scorer(X1_batch, X2)\n",
    "                output = predictor(output).reshape(-1)\n",
    "                # calculate the loss and accuracy\n",
    "                loss = loss_function(output, y_batch)\n",
    "                test_loss += loss.data.item()\n",
    "                # calculate the accuracy\n",
    "                if classif:\n",
    "                    y_pred = output.argmax(dim=1)\n",
    "                    score = (y_pred == y_batch).float().mean()\n",
    "                else:\n",
    "                    score = mean_squared_error(output.detach().cpu(), y_batch.cpu())\n",
    "                test_accuracy += score\n",
    "            print(\"Test loss\", test_loss / len(dataloader_test))\n",
    "            print(\"Test accuracy\", test_accuracy / len(dataloader_test))\n",
    "            print(\"---------------\")\n",
    "    return scorer, predictor, test_accuracy / len(dataloader_test)\n",
    "\n",
    "\n",
    "def train_mlp(X1, y, batch_size, preprocess=False, lr=0.01, n_epochs=100, dim_feedforward=256, train_prop=0.7, n_train=None):\n",
    "    # reshape X to be 3D\n",
    "    X1 = X1.reshape(X1.shape[0], 1, X1.shape[1])\n",
    "    # reshape y to be 2D\n",
    "    y = y.reshape(y.shape[0], 1)\n",
    "    # check if classification or regression\n",
    "    if len(torch.unique(y)) > len(y) / 3:\n",
    "        classif = False\n",
    "        print(\"regression\")\n",
    "    else:\n",
    "        classif = True\n",
    "        print(\"classification\")\n",
    "    if preprocess:\n",
    "        X1 = preprocess_input(X1, y, [], 'power')\n",
    "    # reshape X to be 2D\n",
    "    X1 = X1.reshape(X1.shape[0], X1.shape[2])\n",
    "    # reshape y to be 1D\n",
    "    y = y.reshape(y.shape[0])\n",
    "    if classif:\n",
    "        n_classes = torch.unique(y).shape[0]\n",
    "        print(\"num classes\", n_classes)\n",
    "        predictor = MLP(input_size=X1.shape[1], hidden_size=dim_feedforward, output_size=n_classes, classif=True)\n",
    "    else:\n",
    "        predictor = MLP(input_size=X1.shape[1], hidden_size=dim_feedforward, output_size=1, classif=False)\n",
    "\n",
    "    # move to GPU\n",
    "    predictor = predictor.to(device)\n",
    "    optimizer = optim.Adam([*predictor.parameters()], lr=lr)\n",
    "    # create a dataset\n",
    "    print(X1.shape)\n",
    "    print(y.shape)\n",
    "    assert train_prop is not None or n_train is not None\n",
    "    assert train_prop is None or n_train is None\n",
    "    if n_train is not None:\n",
    "        X1_train = X1[:n_train]\n",
    "        y_train = y[:n_train]\n",
    "        X1_test = X1[n_train:]\n",
    "        y_test = y[n_train:]\n",
    "    else:\n",
    "        X1_train = X1[:int(train_prop * len(X1))]\n",
    "        X1_test = X1[int(train_prop * len(X1)):]\n",
    "        y_train = y[:int(train_prop * len(y))]\n",
    "        y_test = y[int(train_prop * len(y)):]\n",
    "    dataset_train = torch.utils.data.TensorDataset(X1_train, y_train)\n",
    "    dataset_test = torch.utils.data.TensorDataset(X1_test, y_test)\n",
    "    # create a data loader\n",
    "    dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "    if classif:\n",
    "        loss_function = torch.nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        loss_function = torch.nn.MSELoss()\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0\n",
    "        train_score = 0\n",
    "        for X1_batch, y_batch in dataloader_train:\n",
    "            # move to GPU\n",
    "            X1_batch = X1_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            # get the predictions\n",
    "            output = predictor(X1_batch).reshape(-1)\n",
    "            # calculate the loss\n",
    "            loss = loss_function(output, y_batch)\n",
    "            train_loss += loss.data.item()\n",
    "            if classif:\n",
    "                score = (output.argmax(dim=1) == y_batch).float().mean()\n",
    "            else:\n",
    "                score = mean_squared_error(output.detach().cpu(), y_batch.cpu())\n",
    "            train_score += score\n",
    "            #print(\"Train loss\", loss.item())\n",
    "            # backprop\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch\", epoch)\n",
    "            print(\"----------------\")\n",
    "            print(\"Train loss\", train_loss / len(dataloader_train))\n",
    "            print(\"Train score\", train_score / len(dataloader_train))\n",
    "            # calculate the accuracy\n",
    "            print(\"---------------\")\n",
    "            test_loss = 0\n",
    "            test_accuracy = 0\n",
    "            for X1_batch, y_batch in dataloader_test:\n",
    "                # move to GPU\n",
    "                X1_batch = X1_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                # Calculate the predictions\n",
    "                output = predictor(X1_batch).reshape(-1)\n",
    "                # calculate the loss and accuracy\n",
    "                loss = loss_function(output, y_batch)\n",
    "                test_loss += loss.data.item()\n",
    "                # calculate the accuracy\n",
    "                if classif:\n",
    "                    y_pred = output.argmax(dim=1)\n",
    "                    score = (y_pred == y_batch).float().mean()\n",
    "                else:\n",
    "                    score = mean_squared_error(output.detach().cpu(), y_batch.cpu())\n",
    "                test_accuracy += score\n",
    "            print(\"Test loss\", test_loss / len(dataloader_test))\n",
    "            print(\"Test accuracy\", test_accuracy / len(dataloader_test))\n",
    "            print(\"---------------\")\n",
    "    return predictor, test_accuracy / len(dataloader_test)\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDeep(nn.Module):\n",
    "    def __init__(self, n_layers, input_size, hidden_size, output_size, classif=True):\n",
    "        super(MLPDeep, self).__init__()\n",
    "        self.classif = classif\n",
    "        # create the layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(n_layers):\n",
    "            self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "        if self.classif:\n",
    "            out = F.softmax(out, dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = torch.randn(500, 10)\n",
    "X2 = torch.randn(3000, 10)\n",
    "\n",
    "# Create a random function with an MLP\n",
    "f = MLP(input_size=10, hidden_size=100, output_size=1, classif=False)\n",
    "with torch.no_grad():\n",
    "    y = f(X1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Random Forest --\n",
      "Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/1262600036.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with dataset1 0.012089291143772947\n"
     ]
    }
   ],
   "source": [
    "print(\"-- Random Forest --\")\n",
    "#y = f(X2)\n",
    "print(\"Accuracy with dataset1\", compute_accuracy_rf(X1.detach(), y.detach(), 300))\n",
    "#print(\"Accuracy with dataset2\", compute_accuracy_rf(dataset2, y, 1000))\n",
    "#print(\"Accuracy with dataset1 + dataset2\", compute_accuracy_rf(torch.cat((dataset1, dataset2), dim=1), y, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'scorer' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_matching(X1, X2, y, \u001b[39m300\u001b[39;49m, preprocess\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m, n_epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[18], line 30\u001b[0m, in \u001b[0;36mtrain_matching\u001b[0;34m(X1, X2, y, batch_size, preprocess, lr, n_epochs, dim_feedforward, train_prop, n_train, true_scorer)\u001b[0m\n\u001b[1;32m     27\u001b[0m     predictor \u001b[39m=\u001b[39m MLP(input_size\u001b[39m=\u001b[39mX1\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m X2\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], hidden_size\u001b[39m=\u001b[39mdim_feedforward, output_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, classif\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m \u001b[39m# move to GPU\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m scorer \u001b[39m=\u001b[39m scorer\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m predictor \u001b[39m=\u001b[39m predictor\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     32\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam([\u001b[39m*\u001b[39mscorer\u001b[39m.\u001b[39mparameters(), \u001b[39m*\u001b[39mpredictor\u001b[39m.\u001b[39mparameters()], lr\u001b[39m=\u001b[39mlr)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'scorer' referenced before assignment"
     ]
    }
   ],
   "source": [
    "train_matching(X1, X2, y, 300, preprocess=True, lr=0.001, n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pytorch module \n",
    "class OracleScorer(nn.Module):\n",
    "    def __init__(self, n_features, n_features_2, dim_feedforward):\n",
    "        super(OracleScorer, self).__init__()\n",
    "\n",
    "    def forward(self, M1, M2):\n",
    "        scores = []\n",
    "        for i in range(M1.size(0)):\n",
    "                score = torch.exp(-((M1[i].repeat(M2.shape[0], 1) -  M2[:, :-1])**2).sum(dim=1))\n",
    "                scores.append(score)\n",
    "        scores = torch.stack(scores).view(M1.size(0), M2.size(0))\n",
    "        # Normalize scores\n",
    "        scores = F.softmax(scores, dim=1)\n",
    "        M2_avg = scores @ M2\n",
    "        return torch.cat((M1, M2_avg), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0634)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n",
      "---------------\n",
      "y torch.Size([3000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.32000168412923813\n",
      "Train score 0.32000168412923813\n",
      "---------------\n",
      "Test loss 0.36174731904810126\n",
      "Test accuracy 0.3617473163387992\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.22820822149515152\n",
      "Train score 0.22820819169282913\n",
      "---------------\n",
      "Test loss 0.22776450894095682\n",
      "Test accuracy 0.22776450352235275\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.13859032094478607\n",
      "Train score 0.13859032094478607\n",
      "---------------\n",
      "Test loss 0.1514539677988399\n",
      "Test accuracy 0.15145396508953787\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.08367393165826797\n",
      "Train score 0.08367393538355827\n",
      "---------------\n",
      "Test loss 0.0942290567538955\n",
      "Test accuracy 0.09422905539924448\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.04970800690352917\n",
      "Train score 0.04970800317823887\n",
      "---------------\n",
      "Test loss 0.05735083432360129\n",
      "Test accuracy 0.057350835339589554\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.03316370025277138\n",
      "Train score 0.03316369839012623\n",
      "---------------\n",
      "Test loss 0.038346135819500145\n",
      "Test accuracy 0.038346135819500145\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([6000, 10])\n",
      "torch.Size([6000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.3127557049904551\n",
      "Train score 0.31275570179734913\n",
      "---------------\n",
      "Test loss 0.24722449183464051\n",
      "Test accuracy 0.24722449183464051\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.01844677914466177\n",
      "Train score 0.018446779011615684\n",
      "---------------\n",
      "Test loss 0.017500981129705905\n",
      "Test accuracy 0.017500981595367192\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.012764798344245978\n",
      "Train score 0.012764798144676856\n",
      "---------------\n",
      "Test loss 0.013009603321552276\n",
      "Test accuracy 0.013009602949023247\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.01158083469739982\n",
      "Train score 0.011580834564353739\n",
      "---------------\n",
      "Test loss 0.012042783107608557\n",
      "Test accuracy 0.012042783107608557\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.01116582831101758\n",
      "Train score 0.01116582824449454\n",
      "---------------\n",
      "Test loss 0.011796679627150298\n",
      "Test accuracy 0.011796679627150298\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.010879146666931254\n",
      "Train score 0.01087914633431605\n",
      "---------------\n",
      "Test loss 0.011551847867667674\n",
      "Test accuracy 0.01155184768140316\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 1.9695358872413635\n",
      "Train score 1.9695359468460083\n",
      "---------------\n",
      "Test loss 1.2027953429655596\n",
      "Test accuracy 1.2027953754771838\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.23139462620019913\n",
      "Train score 0.23139461874961853\n",
      "---------------\n",
      "Test loss 0.28486938097260217\n",
      "Test accuracy 0.2848693836819042\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.058891868218779564\n",
      "Train score 0.05889187380671501\n",
      "---------------\n",
      "Test loss 0.13563320379365573\n",
      "Test accuracy 0.13563320379365573\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.031436774879693985\n",
      "Train score 0.03143677394837141\n",
      "---------------\n",
      "Test loss 0.10196874764832584\n",
      "Test accuracy 0.10196874764832584\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.018002821132540703\n",
      "Train score 0.018002820201218128\n",
      "---------------\n",
      "Test loss 0.09130629693919962\n",
      "Test accuracy 0.09130629761652513\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.011469095945358276\n",
      "Train score 0.011469095945358276\n",
      "---------------\n",
      "Test loss 0.08819145370613445\n",
      "Test accuracy 0.08819145506078546\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 1.6230353116989136\n",
      "Train score 1.6230353116989136\n",
      "---------------\n",
      "Test loss 1.3956568349491467\n",
      "Test accuracy 1.3956568132747302\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.3472618907690048\n",
      "Train score 0.34726187586784363\n",
      "---------------\n",
      "Test loss 0.3258257914673198\n",
      "Test accuracy 0.32582577250220557\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.15834947675466537\n",
      "Train score 0.15834948420524597\n",
      "---------------\n",
      "Test loss 0.20241695777936417\n",
      "Test accuracy 0.20241695642471313\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.11086664721369743\n",
      "Train score 0.11086665466427803\n",
      "---------------\n",
      "Test loss 0.1567942581393502\n",
      "Test accuracy 0.15679425949400122\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.08256392180919647\n",
      "Train score 0.08256391435861588\n",
      "---------------\n",
      "Test loss 0.12092089449817484\n",
      "Test accuracy 0.12092089382084933\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.06315160915255547\n",
      "Train score 0.06315160915255547\n",
      "---------------\n",
      "Test loss 0.09669680283828215\n",
      "Test accuracy 0.09669680283828215\n",
      "---------------\n",
      "tensor([[-0.1103],\n",
      "        [-0.1103],\n",
      "        [-0.1103],\n",
      "        ...,\n",
      "        [-0.1103],\n",
      "        [-0.1103],\n",
      "        [-0.1103]])\n",
      "Trial 1\n",
      "---------------\n",
      "y torch.Size([3000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.4145529419183731\n",
      "Train score 0.4145529121160507\n",
      "---------------\n",
      "Test loss 0.44251002777706494\n",
      "Test accuracy 0.4425100250677629\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.2856893837451935\n",
      "Train score 0.2856893986463547\n",
      "---------------\n",
      "Test loss 0.28966177187182685\n",
      "Test accuracy 0.28966177864508197\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.16761307418346405\n",
      "Train score 0.16761308163404465\n",
      "---------------\n",
      "Test loss 0.17814076082272964\n",
      "Test accuracy 0.1781407594680786\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.09728269279003143\n",
      "Train score 0.09728268906474113\n",
      "---------------\n",
      "Test loss 0.10278561575846239\n",
      "Test accuracy 0.10278561575846239\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.044847168028354645\n",
      "Train score 0.044847166165709496\n",
      "---------------\n",
      "Test loss 0.056748503988439385\n",
      "Test accuracy 0.05674850432710214\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.02774872165173292\n",
      "Train score 0.027748719789087772\n",
      "---------------\n",
      "Test loss 0.03646445748480884\n",
      "Test accuracy 0.036464458839459854\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([6000, 10])\n",
      "torch.Size([6000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.36466588718550547\n",
      "Train score 0.3646658935717174\n",
      "---------------\n",
      "Test loss 0.31061544716358186\n",
      "Test accuracy 0.3106154352426529\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.017528907595468417\n",
      "Train score 0.017528907928083624\n",
      "---------------\n",
      "Test loss 0.016297310777008533\n",
      "Test accuracy 0.01629731087014079\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.012267558436308588\n",
      "Train score 0.012267558303262507\n",
      "---------------\n",
      "Test loss 0.01262089293450117\n",
      "Test accuracy 0.012620892841368914\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.011439653246530465\n",
      "Train score 0.011439653113484383\n",
      "---------------\n",
      "Test loss 0.011923161335289478\n",
      "Test accuracy 0.011923161335289478\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.011075980761753661\n",
      "Train score 0.011075980894799744\n",
      "---------------\n",
      "Test loss 0.01156199276447296\n",
      "Test accuracy 0.011561992578208447\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.010770798727337803\n",
      "Train score 0.010770798793860845\n",
      "---------------\n",
      "Test loss 0.011448613274842501\n",
      "Test accuracy 0.011448613274842501\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 1.4500120878219604\n",
      "Train score 1.4500121474266052\n",
      "---------------\n",
      "Test loss 0.8817562406713312\n",
      "Test accuracy 0.8817562189969149\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.08259589225053787\n",
      "Train score 0.08259589597582817\n",
      "---------------\n",
      "Test loss 0.12265147201039574\n",
      "Test accuracy 0.12265147336504677\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.032137103378772736\n",
      "Train score 0.032137101516127586\n",
      "---------------\n",
      "Test loss 0.08196875859390605\n",
      "Test accuracy 0.08196875791658055\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.016016805078834295\n",
      "Train score 0.016016804613173008\n",
      "---------------\n",
      "Test loss 0.07265713675455614\n",
      "Test accuracy 0.07265713675455614\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.011296709533780813\n",
      "Train score 0.011296709068119526\n",
      "---------------\n",
      "Test loss 0.06358078054406426\n",
      "Test accuracy 0.063580779528076\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.006133177550509572\n",
      "Train score 0.006133177084848285\n",
      "---------------\n",
      "Test loss 0.06002256443554705\n",
      "Test accuracy 0.06002256545153531\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 1.6814151406288147\n",
      "Train score 1.6814151406288147\n",
      "---------------\n",
      "Test loss 1.3220435922796077\n",
      "Test accuracy 1.3220435814423994\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.365090936422348\n",
      "Train score 0.3650909513235092\n",
      "---------------\n",
      "Test loss 0.41864595359021967\n",
      "Test accuracy 0.4186459481716156\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.16736382991075516\n",
      "Train score 0.16736382991075516\n",
      "---------------\n",
      "Test loss 0.25268323719501495\n",
      "Test accuracy 0.25268322364850476\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.10857828706502914\n",
      "Train score 0.10857828706502914\n",
      "---------------\n",
      "Test loss 0.17880842496048321\n",
      "Test accuracy 0.17880842631513422\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.07293686643242836\n",
      "Train score 0.07293686643242836\n",
      "---------------\n",
      "Test loss 0.1392591500824148\n",
      "Test accuracy 0.13925914737311276\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.07068857923150063\n",
      "Train score 0.07068857364356518\n",
      "---------------\n",
      "Test loss 0.11925687911835584\n",
      "Test accuracy 0.11925687911835584\n",
      "---------------\n",
      "tensor([[-0.1837],\n",
      "        [-0.1837],\n",
      "        [-0.1837],\n",
      "        ...,\n",
      "        [-0.1837],\n",
      "        [-0.1837],\n",
      "        [-0.1837]])\n",
      "Trial 2\n",
      "---------------\n",
      "y torch.Size([3000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.24028385430574417\n",
      "Train score 0.24028384685516357\n",
      "---------------\n",
      "Test loss 0.23221238228407773\n",
      "Test accuracy 0.23221237822012467\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.1047159694135189\n",
      "Train score 0.10471596568822861\n",
      "---------------\n",
      "Test loss 0.1188430894504894\n",
      "Test accuracy 0.11884309215979143\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.06815042532980442\n",
      "Train score 0.06815042346715927\n",
      "---------------\n",
      "Test loss 0.0758385576985099\n",
      "Test accuracy 0.0758385570211844\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.05092303454875946\n",
      "Train score 0.05092302896082401\n",
      "---------------\n",
      "Test loss 0.05048903010108254\n",
      "Test accuracy 0.05048903145573356\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.03091390524059534\n",
      "Train score 0.03091390710324049\n",
      "---------------\n",
      "Test loss 0.035420375114137474\n",
      "Test accuracy 0.035420375114137474\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.02282633725553751\n",
      "Train score 0.022826336324214935\n",
      "---------------\n",
      "Test loss 0.026189775121482937\n",
      "Test accuracy 0.026189774952151558\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([6000, 10])\n",
      "torch.Size([6000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.18809062668255397\n",
      "Train score 0.18809062455381667\n",
      "---------------\n",
      "Test loss 0.1503347188234329\n",
      "Test accuracy 0.1503347188234329\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.014481745593781983\n",
      "Train score 0.014481745660305023\n",
      "---------------\n",
      "Test loss 0.014233032055199147\n",
      "Test accuracy 0.014233032055199147\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.011312875697123153\n",
      "Train score 0.011312875963215317\n",
      "---------------\n",
      "Test loss 0.01169594107195735\n",
      "Test accuracy 0.01169594107195735\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.010561465950948852\n",
      "Train score 0.010561465618333645\n",
      "---------------\n",
      "Test loss 0.011200977489352226\n",
      "Test accuracy 0.01120097739621997\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.010230735476527895\n",
      "Train score 0.010230735410004854\n",
      "---------------\n",
      "Test loss 0.0110017710365355\n",
      "Test accuracy 0.01100177112966776\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.01001597089426858\n",
      "Train score 0.010015970694699458\n",
      "---------------\n",
      "Test loss 0.010829687397927047\n",
      "Test accuracy 0.01082968721166253\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 2.369653642177582\n",
      "Train score 2.369653582572937\n",
      "---------------\n",
      "Test loss 1.6720223426818848\n",
      "Test accuracy 1.6720223318446765\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.23770468682050705\n",
      "Train score 0.23770469427108765\n",
      "---------------\n",
      "Test loss 0.2772040922533382\n",
      "Test accuracy 0.2772040895440362\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.07314680702984333\n",
      "Train score 0.07314680702984333\n",
      "---------------\n",
      "Test loss 0.16133245148442008\n",
      "Test accuracy 0.16133244877511804\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.044839100912213326\n",
      "Train score 0.044839099049568176\n",
      "---------------\n",
      "Test loss 0.10066042772748253\n",
      "Test accuracy 0.10066042975945906\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.025012396275997162\n",
      "Train score 0.025012393482029438\n",
      "---------------\n",
      "Test loss 0.08520804345607758\n",
      "Test accuracy 0.08520804345607758\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.014985326677560806\n",
      "Train score 0.014985327143222094\n",
      "---------------\n",
      "Test loss 0.0732743963599205\n",
      "Test accuracy 0.07327439568259499\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 4.007660627365112\n",
      "Train score 4.007660388946533\n",
      "---------------\n",
      "Test loss 3.3483076745813545\n",
      "Test accuracy 3.348307587883689\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.7898899614810944\n",
      "Train score 0.7898899614810944\n",
      "---------------\n",
      "Test loss 0.852919421412728\n",
      "Test accuracy 0.852919415994124\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.333770215511322\n",
      "Train score 0.3337702006101608\n",
      "---------------\n",
      "Test loss 0.35239883715456183\n",
      "Test accuracy 0.35239884528246795\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.1454218551516533\n",
      "Train score 0.1454218588769436\n",
      "---------------\n",
      "Test loss 0.22572847658937628\n",
      "Test accuracy 0.22572847523472525\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.13627668470144272\n",
      "Train score 0.13627668470144272\n",
      "---------------\n",
      "Test loss 0.176653576168147\n",
      "Test accuracy 0.17665357345884497\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.09102093428373337\n",
      "Train score 0.09102093800902367\n",
      "---------------\n",
      "Test loss 0.1465919024565003\n",
      "Test accuracy 0.14659190516580234\n",
      "---------------\n",
      "tensor([[-0.2921],\n",
      "        [-0.2921],\n",
      "        [-0.2921],\n",
      "        ...,\n",
      "        [-0.2921],\n",
      "        [-0.2921],\n",
      "        [-0.2921]])\n",
      "Trial 3\n",
      "---------------\n",
      "y torch.Size([3000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.32043421268463135\n",
      "Train score 0.32043419778347015\n",
      "---------------\n",
      "Test loss 0.32083616202527826\n",
      "Test accuracy 0.32083616202527826\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.24358484148979187\n",
      "Train score 0.24358487129211426\n",
      "---------------\n",
      "Test loss 0.23485315929759631\n",
      "Test accuracy 0.2348531647162004\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.15826620906591415\n",
      "Train score 0.15826620906591415\n",
      "---------------\n",
      "Test loss 0.16775127703493292\n",
      "Test accuracy 0.16775128109888596\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.1116127036511898\n",
      "Train score 0.1116126999258995\n",
      "---------------\n",
      "Test loss 0.11305536397478798\n",
      "Test accuracy 0.113055365329439\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.06074613891541958\n",
      "Train score 0.06074614077806473\n",
      "---------------\n",
      "Test loss 0.07098537344824184\n",
      "Test accuracy 0.07098537548021837\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.03592587262392044\n",
      "Train score 0.03592587262392044\n",
      "---------------\n",
      "Test loss 0.0430563898249106\n",
      "Test accuracy 0.04305638948624784\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([6000, 10])\n",
      "torch.Size([6000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.3691156080790928\n",
      "Train score 0.3691156123365675\n",
      "---------------\n",
      "Test loss 0.31681337356567385\n",
      "Test accuracy 0.31681337356567385\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.019268254350338663\n",
      "Train score 0.019268254217292582\n",
      "---------------\n",
      "Test loss 0.018576535396277905\n",
      "Test accuracy 0.01857653521001339\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.01243392624227064\n",
      "Train score 0.012433925909655434\n",
      "---------------\n",
      "Test loss 0.012934471294283868\n",
      "Test accuracy 0.012934471387416125\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.0111852327494749\n",
      "Train score 0.011185233082090105\n",
      "---------------\n",
      "Test loss 0.011907395347952843\n",
      "Test accuracy 0.011907395161688327\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.010680338168250663\n",
      "Train score 0.010680338035204582\n",
      "---------------\n",
      "Test loss 0.01143184918910265\n",
      "Test accuracy 0.011431848909705878\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.01042784923421485\n",
      "Train score 0.010427849300737892\n",
      "---------------\n",
      "Test loss 0.011152873653918505\n",
      "Test accuracy 0.01115287384018302\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 2.1899920105934143\n",
      "Train score 2.1899919509887695\n",
      "---------------\n",
      "Test loss 1.3694203008304944\n",
      "Test accuracy 1.3694202899932861\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.10370398312807083\n",
      "Train score 0.10370398312807083\n",
      "---------------\n",
      "Test loss 0.12414902380921623\n",
      "Test accuracy 0.12414902177723972\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.039050256833434105\n",
      "Train score 0.039050254970788956\n",
      "---------------\n",
      "Test loss 0.0918516760522669\n",
      "Test accuracy 0.09185167672959241\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.01923952531069517\n",
      "Train score 0.019239524379372597\n",
      "---------------\n",
      "Test loss 0.07123826037753712\n",
      "Test accuracy 0.07123825834556059\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.01667285617440939\n",
      "Train score 0.01667285803705454\n",
      "---------------\n",
      "Test loss 0.06590771539644762\n",
      "Test accuracy 0.06590771200982007\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.011386731173843145\n",
      "Train score 0.011386732570827007\n",
      "---------------\n",
      "Test loss 0.061598508872769096\n",
      "Test accuracy 0.061598508872769096\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 2.0978278517723083\n",
      "Train score 2.0978278517723083\n",
      "---------------\n",
      "Test loss 1.987138943238692\n",
      "Test accuracy 1.987138943238692\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.5811668634414673\n",
      "Train score 0.5811668038368225\n",
      "---------------\n",
      "Test loss 0.5840898318724199\n",
      "Test accuracy 0.584089842709628\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.25780072063207626\n",
      "Train score 0.25780072063207626\n",
      "---------------\n",
      "Test loss 0.31685636937618256\n",
      "Test accuracy 0.3168563747947866\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.15989042073488235\n",
      "Train score 0.15989043191075325\n",
      "---------------\n",
      "Test loss 0.2191644392230294\n",
      "Test accuracy 0.21916443651372736\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.13354717940092087\n",
      "Train score 0.13354717940092087\n",
      "---------------\n",
      "Test loss 0.1657955294305628\n",
      "Test accuracy 0.16579552807591177\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.10308903455734253\n",
      "Train score 0.10308902710676193\n",
      "---------------\n",
      "Test loss 0.12891275435686111\n",
      "Test accuracy 0.12891275503418662\n",
      "---------------\n",
      "tensor([[0.0485],\n",
      "        [0.0485],\n",
      "        [0.0485],\n",
      "        ...,\n",
      "        [0.0485],\n",
      "        [0.0485],\n",
      "        [0.0485]])\n",
      "Trial 4\n",
      "---------------\n",
      "y torch.Size([3000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.4048348665237427\n",
      "Train score 0.40483488142490387\n",
      "---------------\n",
      "Test loss 0.38562348214062775\n",
      "Test accuracy 0.3856234767220237\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.23244361579418182\n",
      "Train score 0.23244361579418182\n",
      "---------------\n",
      "Test loss 0.22799327698620883\n",
      "Test accuracy 0.2279932742769068\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.10364244505763054\n",
      "Train score 0.10364243015646935\n",
      "---------------\n",
      "Test loss 0.1316739855842157\n",
      "Test accuracy 0.1316739876161922\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.06956333294510841\n",
      "Train score 0.06956333294510841\n",
      "---------------\n",
      "Test loss 0.07743864303285425\n",
      "Test accuracy 0.07743864371017976\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.03767062537372112\n",
      "Train score 0.03767062723636627\n",
      "---------------\n",
      "Test loss 0.04778980802405964\n",
      "Test accuracy 0.047789809040047905\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.030706925317645073\n",
      "Train score 0.030706927180290222\n",
      "---------------\n",
      "Test loss 0.033763543110002174\n",
      "Test accuracy 0.03376354378732768\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([6000, 10])\n",
      "torch.Size([6000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.17083533321108138\n",
      "Train score 0.17083533533981868\n",
      "---------------\n",
      "Test loss 0.12775849029421807\n",
      "Test accuracy 0.12775849252939225\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.015641555057040284\n",
      "Train score 0.015641554990517243\n",
      "---------------\n",
      "Test loss 0.015597644355148077\n",
      "Test accuracy 0.01559764426201582\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.012337790469505958\n",
      "Train score 0.012337790469505958\n",
      "---------------\n",
      "Test loss 0.012109620217233896\n",
      "Test accuracy 0.012109620217233896\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.011441019297178303\n",
      "Train score 0.011441019496747426\n",
      "---------------\n",
      "Test loss 0.011088467948138715\n",
      "Test accuracy 0.011088467948138715\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.010990068449505739\n",
      "Train score 0.01099006864907486\n",
      "---------------\n",
      "Test loss 0.010709497705101967\n",
      "Test accuracy 0.010709497891366482\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.010717505855219705\n",
      "Train score 0.010717505855219705\n",
      "---------------\n",
      "Test loss 0.010491270385682584\n",
      "Test accuracy 0.010491270199418068\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 2.81760573387146\n",
      "Train score 2.8176056146621704\n",
      "---------------\n",
      "Test loss 2.0336092818867075\n",
      "Test accuracy 2.0336092818867075\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.18610577285289764\n",
      "Train score 0.18610577285289764\n",
      "---------------\n",
      "Test loss 0.20552768219601025\n",
      "Test accuracy 0.20552768490531229\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.070736363530159\n",
      "Train score 0.070736363530159\n",
      "---------------\n",
      "Test loss 0.12283562326973135\n",
      "Test accuracy 0.12283562462438237\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.04207748547196388\n",
      "Train score 0.04207748547196388\n",
      "---------------\n",
      "Test loss 0.09235460311174393\n",
      "Test accuracy 0.09235460311174393\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.023005638271570206\n",
      "Train score 0.023005638271570206\n",
      "---------------\n",
      "Test loss 0.0775079063393853\n",
      "Test accuracy 0.07750790769403632\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.015737459063529968\n",
      "Train score 0.01573745720088482\n",
      "---------------\n",
      "Test loss 0.07028373398564079\n",
      "Test accuracy 0.07028373500162904\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 5.414526700973511\n",
      "Train score 5.4145262241363525\n",
      "---------------\n",
      "Test loss 4.566483931107954\n",
      "Test accuracy 4.566483801061457\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 1.6268773674964905\n",
      "Train score 1.6268774271011353\n",
      "---------------\n",
      "Test loss 1.2812137387015603\n",
      "Test accuracy 1.2812137495387683\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.5850812494754791\n",
      "Train score 0.5850812196731567\n",
      "---------------\n",
      "Test loss 0.5995832735841925\n",
      "Test accuracy 0.5995832627469843\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.33649712800979614\n",
      "Train score 0.33649711310863495\n",
      "---------------\n",
      "Test loss 0.3879387785087932\n",
      "Test accuracy 0.3879387785087932\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.19846950471401215\n",
      "Train score 0.19846951216459274\n",
      "---------------\n",
      "Test loss 0.3097066174853932\n",
      "Test accuracy 0.30970660664818506\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.15666572749614716\n",
      "Train score 0.15666572749614716\n",
      "---------------\n",
      "Test loss 0.252609445290132\n",
      "Test accuracy 0.25260944258082996\n",
      "---------------\n",
      "tensor([[-0.2347],\n",
      "        [-0.2347],\n",
      "        [-0.2347],\n",
      "        ...,\n",
      "        [-0.2347],\n",
      "        [-0.2347],\n",
      "        [-0.2347]])\n",
      "Trial 5\n",
      "---------------\n",
      "y torch.Size([3000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.31349098682403564\n",
      "Train score 0.31349097192287445\n",
      "---------------\n",
      "Test loss 0.3799075728113001\n",
      "Test accuracy 0.3799075592647899\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.1862764060497284\n",
      "Train score 0.1862763911485672\n",
      "---------------\n",
      "Test loss 0.24901989508758893\n",
      "Test accuracy 0.24901989779689096\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.13662638515233994\n",
      "Train score 0.13662639260292053\n",
      "---------------\n",
      "Test loss 0.16321815414862198\n",
      "Test accuracy 0.163218155503273\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.07369637116789818\n",
      "Train score 0.07369636744260788\n",
      "---------------\n",
      "Test loss 0.09796986999836835\n",
      "Test accuracy 0.09796986999836835\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.040414340794086456\n",
      "Train score 0.040414340794086456\n",
      "---------------\n",
      "Test loss 0.05736921524459666\n",
      "Test accuracy 0.057369216260584915\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.026380280032753944\n",
      "Train score 0.02638028096407652\n",
      "---------------\n",
      "Test loss 0.03651516308838671\n",
      "Test accuracy 0.036515162072398445\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([6000, 10])\n",
      "torch.Size([6000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.3209176744733538\n",
      "Train score 0.32091767873082844\n",
      "---------------\n",
      "Test loss 0.2596732392907143\n",
      "Test accuracy 0.25967323780059814\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.020271065911012038\n",
      "Train score 0.02027106631015028\n",
      "---------------\n",
      "Test loss 0.019144124910235406\n",
      "Test accuracy 0.019144124910235406\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.013227620627731085\n",
      "Train score 0.013227620561208044\n",
      "---------------\n",
      "Test loss 0.013177028857171535\n",
      "Test accuracy 0.01317702904343605\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.011883166086460863\n",
      "Train score 0.011883166219506944\n",
      "---------------\n",
      "Test loss 0.011935882829129696\n",
      "Test accuracy 0.011935883108526469\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.011352867553276675\n",
      "Train score 0.011352867752845799\n",
      "---------------\n",
      "Test loss 0.011546698398888111\n",
      "Test accuracy 0.011546698398888111\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.011106585618108511\n",
      "Train score 0.011106585352016347\n",
      "---------------\n",
      "Test loss 0.01129877557978034\n",
      "Test accuracy 0.011298775486648083\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 1.3974449634552002\n",
      "Train score 1.3974449038505554\n",
      "---------------\n",
      "Test loss 1.12537311965769\n",
      "Test accuracy 1.125373125076294\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.1443541944026947\n",
      "Train score 0.1443541944026947\n",
      "---------------\n",
      "Test loss 0.19052501158280807\n",
      "Test accuracy 0.19052501022815704\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.05712619796395302\n",
      "Train score 0.05712619982659817\n",
      "---------------\n",
      "Test loss 0.12479801001873883\n",
      "Test accuracy 0.12479801205071536\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.03087477758526802\n",
      "Train score 0.03087477758526802\n",
      "---------------\n",
      "Test loss 0.09862141853029077\n",
      "Test accuracy 0.09862142123959282\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.019403609447181225\n",
      "Train score 0.019403609447181225\n",
      "---------------\n",
      "Test loss 0.09004875475710089\n",
      "Test accuracy 0.09004875543442639\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.012396435718983412\n",
      "Train score 0.012396436184644699\n",
      "---------------\n",
      "Test loss 0.08944774012673985\n",
      "Test accuracy 0.08944774012673985\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 1.4816654324531555\n",
      "Train score 1.4816653728485107\n",
      "---------------\n",
      "Test loss 1.551232933998108\n",
      "Test accuracy 1.551232933998108\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.42803584039211273\n",
      "Train score 0.42803584039211273\n",
      "---------------\n",
      "Test loss 0.524008496241136\n",
      "Test accuracy 0.5240085097876462\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.1924639716744423\n",
      "Train score 0.1924639716744423\n",
      "---------------\n",
      "Test loss 0.3002056560733102\n",
      "Test accuracy 0.300205645236102\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.14198028296232224\n",
      "Train score 0.14198027551174164\n",
      "---------------\n",
      "Test loss 0.21943109008398923\n",
      "Test accuracy 0.21943109279329126\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.10290103405714035\n",
      "Train score 0.10290103033185005\n",
      "---------------\n",
      "Test loss 0.16934288496320898\n",
      "Test accuracy 0.16934288902716202\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.07577375322580338\n",
      "Train score 0.07577374950051308\n",
      "---------------\n",
      "Test loss 0.1407400525429032\n",
      "Test accuracy 0.14074005051092667\n",
      "---------------\n",
      "tensor([[-0.2354],\n",
      "        [-0.2354],\n",
      "        [-0.2354],\n",
      "        ...,\n",
      "        [-0.2354],\n",
      "        [-0.2354],\n",
      "        [-0.2354]])\n",
      "Trial 6\n",
      "---------------\n",
      "y torch.Size([3000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.7052814662456512\n",
      "Train score 0.7052814662456512\n",
      "---------------\n",
      "Test loss 0.7418992465192621\n",
      "Test accuracy 0.74189923026345\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.5900329053401947\n",
      "Train score 0.5900328904390335\n",
      "---------------\n",
      "Test loss 0.49326007745482703\n",
      "Test accuracy 0.4932600937106393\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.35983729362487793\n",
      "Train score 0.3598373383283615\n",
      "---------------\n",
      "Test loss 0.34784540804949676\n",
      "Test accuracy 0.34784541075879877\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.22971058636903763\n",
      "Train score 0.22971057146787643\n",
      "---------------\n",
      "Test loss 0.24588284438306635\n",
      "Test accuracy 0.24588283896446228\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.19320933520793915\n",
      "Train score 0.19320934265851974\n",
      "---------------\n",
      "Test loss 0.16859888624061237\n",
      "Test accuracy 0.1685988875952634\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.1083579957485199\n",
      "Train score 0.1083579920232296\n",
      "---------------\n",
      "Test loss 0.11109547046097842\n",
      "Test accuracy 0.11109547046097842\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([6000, 10])\n",
      "torch.Size([6000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.6084719853741782\n",
      "Train score 0.6084719938891274\n",
      "---------------\n",
      "Test loss 0.4960975408554077\n",
      "Test accuracy 0.49609753787517546\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.022072833563600267\n",
      "Train score 0.02207283369664635\n",
      "---------------\n",
      "Test loss 0.02099690996110439\n",
      "Test accuracy 0.02099690940231085\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.014308265277317591\n",
      "Train score 0.014308264878179346\n",
      "---------------\n",
      "Test loss 0.014172741677612066\n",
      "Test accuracy 0.014172741305083036\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.012296471212591444\n",
      "Train score 0.012296471212591444\n",
      "---------------\n",
      "Test loss 0.012401838973164558\n",
      "Test accuracy 0.0124018388800323\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.011547944375446864\n",
      "Train score 0.011547944375446864\n",
      "---------------\n",
      "Test loss 0.011985148116946221\n",
      "Test accuracy 0.011985148116946221\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.011227316289607967\n",
      "Train score 0.01122731635613101\n",
      "---------------\n",
      "Test loss 0.011740469187498093\n",
      "Test accuracy 0.011740469187498093\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 2.431558132171631\n",
      "Train score 2.4315580129623413\n",
      "---------------\n",
      "Test loss 1.6387603066184304\n",
      "Test accuracy 1.6387603066184304\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.15004932135343552\n",
      "Train score 0.15004931390285492\n",
      "---------------\n",
      "Test loss 0.21284822035919537\n",
      "Test accuracy 0.2128482230684974\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.062428295612335205\n",
      "Train score 0.06242829188704491\n",
      "---------------\n",
      "Test loss 0.12755457040938464\n",
      "Test accuracy 0.1275545683774081\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.031454844400286674\n",
      "Train score 0.031454846262931824\n",
      "---------------\n",
      "Test loss 0.1076421317729083\n",
      "Test accuracy 0.10764213041825728\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.014519346877932549\n",
      "Train score 0.014519346412271261\n",
      "---------------\n",
      "Test loss 0.09390155158259651\n",
      "Test accuracy 0.09390154819596898\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.010225606616586447\n",
      "Train score 0.010225606616586447\n",
      "---------------\n",
      "Test loss 0.08483704314990477\n",
      "Test accuracy 0.08483704247257927\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 3.245396137237549\n",
      "Train score 3.2453958988189697\n",
      "---------------\n",
      "Test loss 2.547919273376465\n",
      "Test accuracy 2.5479191433299673\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.5970829129219055\n",
      "Train score 0.5970829725265503\n",
      "---------------\n",
      "Test loss 0.5509422258897261\n",
      "Test accuracy 0.5509422367269342\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.286140538752079\n",
      "Train score 0.2861405164003372\n",
      "---------------\n",
      "Test loss 0.24588611992922696\n",
      "Test accuracy 0.2458861158652739\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.14698921144008636\n",
      "Train score 0.14698921144008636\n",
      "---------------\n",
      "Test loss 0.1868783411654559\n",
      "Test accuracy 0.18687833845615387\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.11631389334797859\n",
      "Train score 0.116313885897398\n",
      "---------------\n",
      "Test loss 0.14683577147397128\n",
      "Test accuracy 0.14683577011932025\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.0840371735394001\n",
      "Train score 0.0840371772646904\n",
      "---------------\n",
      "Test loss 0.11116419935768301\n",
      "Test accuracy 0.11116420206698505\n",
      "---------------\n",
      "tensor([[-0.3101],\n",
      "        [-0.3101],\n",
      "        [-0.3101],\n",
      "        ...,\n",
      "        [-0.3101],\n",
      "        [-0.3101],\n",
      "        [-0.3101]])\n",
      "Trial 7\n",
      "---------------\n",
      "y torch.Size([3000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.49050286412239075\n",
      "Train score 0.49050289392471313\n",
      "---------------\n",
      "Test loss 0.4324419390071522\n",
      "Test accuracy 0.4324419390071522\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.3015555739402771\n",
      "Train score 0.3015555888414383\n",
      "---------------\n",
      "Test loss 0.29948135397650977\n",
      "Test accuracy 0.2994813485579057\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.1934283822774887\n",
      "Train score 0.19342836737632751\n",
      "---------------\n",
      "Test loss 0.19270931319756943\n",
      "Test accuracy 0.1927093118429184\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.11252174898982048\n",
      "Train score 0.11252175271511078\n",
      "---------------\n",
      "Test loss 0.11612021990797737\n",
      "Test accuracy 0.11612021787600084\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.06264529749751091\n",
      "Train score 0.06264530122280121\n",
      "---------------\n",
      "Test loss 0.06563637541099028\n",
      "Test accuracy 0.06563637473366478\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.03223264683037996\n",
      "Train score 0.03223264683037996\n",
      "---------------\n",
      "Test loss 0.0384590361605991\n",
      "Test accuracy 0.03845903582193635\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([6000, 10])\n",
      "torch.Size([6000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.4135033743722098\n",
      "Train score 0.4135033743722098\n",
      "---------------\n",
      "Test loss 0.3532329946756363\n",
      "Test accuracy 0.3532329976558685\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.023155268813882555\n",
      "Train score 0.023155268813882555\n",
      "---------------\n",
      "Test loss 0.023067111894488335\n",
      "Test accuracy 0.023067112267017364\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.014448708455477442\n",
      "Train score 0.014448708522000484\n",
      "---------------\n",
      "Test loss 0.015413893945515155\n",
      "Test accuracy 0.015413893945515155\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.01236540371818202\n",
      "Train score 0.01236540371818202\n",
      "---------------\n",
      "Test loss 0.013367041293531657\n",
      "Test accuracy 0.013367041293531657\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.011499874626419373\n",
      "Train score 0.011499874426850252\n",
      "---------------\n",
      "Test loss 0.012600069772452116\n",
      "Test accuracy 0.012600069772452116\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.011101323845131057\n",
      "Train score 0.01110132404470018\n",
      "---------------\n",
      "Test loss 0.012204424664378166\n",
      "Test accuracy 0.012204424291849137\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 1.5301024317741394\n",
      "Train score 1.5301024913787842\n",
      "---------------\n",
      "Test loss 1.0438132882118225\n",
      "Test accuracy 1.0438132882118225\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.09565309062600136\n",
      "Train score 0.09565309435129166\n",
      "---------------\n",
      "Test loss 0.14936221526427704\n",
      "Test accuracy 0.14936221729625354\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.05091357231140137\n",
      "Train score 0.05091357231140137\n",
      "---------------\n",
      "Test loss 0.10785453766584396\n",
      "Test accuracy 0.10785453698851845\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.02185558807104826\n",
      "Train score 0.021855587139725685\n",
      "---------------\n",
      "Test loss 0.09436312114650552\n",
      "Test accuracy 0.09436312250115654\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.016260888427495956\n",
      "Train score 0.016260888427495956\n",
      "---------------\n",
      "Test loss 0.08240839805115353\n",
      "Test accuracy 0.0824083990671418\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.009066139347851276\n",
      "Train score 0.009066139347851276\n",
      "---------------\n",
      "Test loss 0.08165675469420174\n",
      "Test accuracy 0.08165675469420174\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 3.0208410024642944\n",
      "Train score 3.020841121673584\n",
      "---------------\n",
      "Test loss 2.945849071849476\n",
      "Test accuracy 2.945848963477395\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 1.0623565018177032\n",
      "Train score 1.0623565018177032\n",
      "---------------\n",
      "Test loss 1.0207748792388223\n",
      "Test accuracy 1.0207749063318425\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.4848734736442566\n",
      "Train score 0.4848734438419342\n",
      "---------------\n",
      "Test loss 0.4738622795451771\n",
      "Test accuracy 0.47386227683587506\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.25905779004096985\n",
      "Train score 0.25905778259038925\n",
      "---------------\n",
      "Test loss 0.3004915849729018\n",
      "Test accuracy 0.30049159851941193\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.16011104732751846\n",
      "Train score 0.16011103987693787\n",
      "---------------\n",
      "Test loss 0.22244669632478195\n",
      "Test accuracy 0.2224466936154799\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.12830416858196259\n",
      "Train score 0.12830416858196259\n",
      "---------------\n",
      "Test loss 0.17787461118264633\n",
      "Test accuracy 0.17787461389194836\n",
      "---------------\n",
      "tensor([[-0.0315],\n",
      "        [-0.0315],\n",
      "        [-0.0315],\n",
      "        ...,\n",
      "        [-0.0315],\n",
      "        [-0.0315],\n",
      "        [-0.0315]])\n",
      "Trial 8\n",
      "---------------\n",
      "y torch.Size([3000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.3204795569181442\n",
      "Train score 0.3204795569181442\n",
      "---------------\n",
      "Test loss 0.3236564072695645\n",
      "Test accuracy 0.32365640185096045\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.18984144926071167\n",
      "Train score 0.18984145671129227\n",
      "---------------\n",
      "Test loss 0.20446733453057028\n",
      "Test accuracy 0.20446733859452335\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.125140231102705\n",
      "Train score 0.125140231102705\n",
      "---------------\n",
      "Test loss 0.134990163824775\n",
      "Test accuracy 0.13499016111547296\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.08157490193843842\n",
      "Train score 0.08157490193843842\n",
      "---------------\n",
      "Test loss 0.09020821750164032\n",
      "Test accuracy 0.09020821885629134\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.048788635060191154\n",
      "Train score 0.048788633197546005\n",
      "---------------\n",
      "Test loss 0.05868974192575975\n",
      "Test accuracy 0.058689740909771485\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.03612168878316879\n",
      "Train score 0.036121685057878494\n",
      "---------------\n",
      "Test loss 0.04229831526225263\n",
      "Test accuracy 0.04229831526225263\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([6000, 10])\n",
      "torch.Size([6000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.5791838786431721\n",
      "Train score 0.5791838850293841\n",
      "---------------\n",
      "Test loss 0.47616455554962156\n",
      "Test accuracy 0.47616454362869265\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.03866955331925835\n",
      "Train score 0.03866955318621227\n",
      "---------------\n",
      "Test loss 0.034461624920368195\n",
      "Test accuracy 0.0344616238027811\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.01637880743614265\n",
      "Train score 0.016378807901803936\n",
      "---------------\n",
      "Test loss 0.016425379458814858\n",
      "Test accuracy 0.016425379551947117\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.013098889429654394\n",
      "Train score 0.013098889695746558\n",
      "---------------\n",
      "Test loss 0.013697002921253443\n",
      "Test accuracy 0.0136970030143857\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.012144430607025112\n",
      "Train score 0.01214443047397903\n",
      "---------------\n",
      "Test loss 0.012845887430012226\n",
      "Test accuracy 0.012845887243747712\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.011651594723973955\n",
      "Train score 0.01165159439135875\n",
      "---------------\n",
      "Test loss 0.012329838704317808\n",
      "Test accuracy 0.012329838797450065\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 2.221899628639221\n",
      "Train score 2.2218995094299316\n",
      "---------------\n",
      "Test loss 1.2714821208607068\n",
      "Test accuracy 1.2714820991862903\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.152253620326519\n",
      "Train score 0.1522536277770996\n",
      "---------------\n",
      "Test loss 0.23408654467626053\n",
      "Test accuracy 0.23408655686811966\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.050592631101608276\n",
      "Train score 0.05059262737631798\n",
      "---------------\n",
      "Test loss 0.15188544717702\n",
      "Test accuracy 0.15188544717702\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.02306266501545906\n",
      "Train score 0.023062664084136486\n",
      "---------------\n",
      "Test loss 0.12807028740644455\n",
      "Test accuracy 0.12807028740644455\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.014869781211018562\n",
      "Train score 0.014869780279695988\n",
      "---------------\n",
      "Test loss 0.10669525983658704\n",
      "Test accuracy 0.10669526051391255\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.009810259565711021\n",
      "Train score 0.009810259565711021\n",
      "---------------\n",
      "Test loss 0.10313166542486711\n",
      "Test accuracy 0.1031316647475416\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 1.2044214308261871\n",
      "Train score 1.2044215202331543\n",
      "---------------\n",
      "Test loss 1.3760810006748547\n",
      "Test accuracy 1.3760810115120627\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.34659576416015625\n",
      "Train score 0.34659576416015625\n",
      "---------------\n",
      "Test loss 0.5087256269021467\n",
      "Test accuracy 0.5087256350300529\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.20750703662633896\n",
      "Train score 0.20750702917575836\n",
      "---------------\n",
      "Test loss 0.3214922547340393\n",
      "Test accuracy 0.3214922438968312\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.12303629145026207\n",
      "Train score 0.12303629517555237\n",
      "---------------\n",
      "Test loss 0.2252096181566065\n",
      "Test accuracy 0.2252096181566065\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.07890765368938446\n",
      "Train score 0.07890765741467476\n",
      "---------------\n",
      "Test loss 0.17343110658905722\n",
      "Test accuracy 0.17343110523440622\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.048101840540766716\n",
      "Train score 0.048101844266057014\n",
      "---------------\n",
      "Test loss 0.1357752721418034\n",
      "Test accuracy 0.13577527078715237\n",
      "---------------\n",
      "tensor([[-0.2956],\n",
      "        [-0.2956],\n",
      "        [-0.2956],\n",
      "        ...,\n",
      "        [-0.2956],\n",
      "        [-0.2956],\n",
      "        [-0.2956]])\n",
      "Trial 9\n",
      "---------------\n",
      "y torch.Size([3000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.5273138880729675\n",
      "Train score 0.5273138880729675\n",
      "---------------\n",
      "Test loss 0.49675325642932544\n",
      "Test accuracy 0.49675324288281525\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.3026838004589081\n",
      "Train score 0.3026838004589081\n",
      "---------------\n",
      "Test loss 0.3028386208144101\n",
      "Test accuracy 0.30283861539580603\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.18783602118492126\n",
      "Train score 0.18783602863550186\n",
      "---------------\n",
      "Test loss 0.18939918008717624\n",
      "Test accuracy 0.18939918144182724\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.12587923929095268\n",
      "Train score 0.12587923929095268\n",
      "---------------\n",
      "Test loss 0.12021098285913467\n",
      "Test accuracy 0.12021098285913467\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.07038483023643494\n",
      "Train score 0.07038483396172523\n",
      "---------------\n",
      "Test loss 0.07547620683908463\n",
      "Test accuracy 0.07547620954838666\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.05612252838909626\n",
      "Train score 0.05612252652645111\n",
      "---------------\n",
      "Test loss 0.051450019871646706\n",
      "Test accuracy 0.051450019532983955\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31826/345646686.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "torch.Size([6000, 10])\n",
      "torch.Size([6000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 0.3317602553537914\n",
      "Train score 0.33176024683884214\n",
      "---------------\n",
      "Test loss 0.2777900382876396\n",
      "Test accuracy 0.2777900367975235\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.023216219219778265\n",
      "Train score 0.023216219352824346\n",
      "---------------\n",
      "Test loss 0.023221317678689957\n",
      "Test accuracy 0.02322131711989641\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.014025324955582619\n",
      "Train score 0.014025324622967414\n",
      "---------------\n",
      "Test loss 0.01484165182337165\n",
      "Test accuracy 0.01484165182337165\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.011632578114845924\n",
      "Train score 0.011632578181368964\n",
      "---------------\n",
      "Test loss 0.012700936943292617\n",
      "Test accuracy 0.012700936943292617\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.010782539378851652\n",
      "Train score 0.010782539578420776\n",
      "---------------\n",
      "Test loss 0.011884017195552588\n",
      "Test accuracy 0.011884017288684845\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.010344791292612041\n",
      "Train score 0.010344791558704205\n",
      "---------------\n",
      "Test loss 0.01161009157076478\n",
      "Test accuracy 0.011610091384500264\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 8.062512397766113\n",
      "Train score 8.062511920928955\n",
      "---------------\n",
      "Test loss 3.189894979650324\n",
      "Test accuracy 3.1898950013247402\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 0.29950951039791107\n",
      "Train score 0.29950951039791107\n",
      "---------------\n",
      "Test loss 0.22617464444854044\n",
      "Test accuracy 0.22617464715784247\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.11895859614014626\n",
      "Train score 0.11895859614014626\n",
      "---------------\n",
      "Test loss 0.14761115339669315\n",
      "Test accuracy 0.14761115204204212\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.09130213409662247\n",
      "Train score 0.09130212664604187\n",
      "---------------\n",
      "Test loss 0.0941635702144016\n",
      "Test accuracy 0.09416356953707608\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.051267094910144806\n",
      "Train score 0.05126709304749966\n",
      "---------------\n",
      "Test loss 0.08078653162175958\n",
      "Test accuracy 0.0807865322990851\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.033754657953977585\n",
      "Train score 0.03375465888530016\n",
      "---------------\n",
      "Test loss 0.07049348374659364\n",
      "Test accuracy 0.07049348679455844\n",
      "---------------\n",
      "regression\n",
      "torch.Size([3000, 10])\n",
      "torch.Size([3000])\n",
      "Epoch 0\n",
      "----------------\n",
      "Train loss 5.548579216003418\n",
      "Train score 5.548578977584839\n",
      "---------------\n",
      "Test loss 4.491727092049339\n",
      "Test accuracy 4.491727048700506\n",
      "---------------\n",
      "Epoch 10\n",
      "----------------\n",
      "Train loss 1.503180742263794\n",
      "Train score 1.503180742263794\n",
      "---------------\n",
      "Test loss 1.298011844808405\n",
      "Test accuracy 1.298011833971197\n",
      "---------------\n",
      "Epoch 20\n",
      "----------------\n",
      "Train loss 0.5454433560371399\n",
      "Train score 0.5454433262348175\n",
      "---------------\n",
      "Test loss 0.5389831418340857\n",
      "Test accuracy 0.5389831228689714\n",
      "---------------\n",
      "Epoch 30\n",
      "----------------\n",
      "Train loss 0.3172660768032074\n",
      "Train score 0.3172660768032074\n",
      "---------------\n",
      "Test loss 0.39452610232613305\n",
      "Test accuracy 0.39452610232613305\n",
      "---------------\n",
      "Epoch 40\n",
      "----------------\n",
      "Train loss 0.23709921538829803\n",
      "Train score 0.23709920048713684\n",
      "---------------\n",
      "Test loss 0.3248442194678567\n",
      "Test accuracy 0.3248442167585546\n",
      "---------------\n",
      "Epoch 50\n",
      "----------------\n",
      "Train loss 0.1919878050684929\n",
      "Train score 0.1919877827167511\n",
      "---------------\n",
      "Test loss 0.26209264451807196\n",
      "Test accuracy 0.26209265941923315\n",
      "---------------\n",
      "tensor([[0.2693],\n",
      "        [0.2693],\n",
      "        [0.2693],\n",
      "        ...,\n",
      "        [0.2693],\n",
      "        [0.2693],\n",
      "        [0.2693]])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "n_trials = 10\n",
    "res_rf_X1 = np.zeros(n_trials)\n",
    "res_mlp_X1 = np.zeros(n_trials)\n",
    "res_rf_X1_large = np.zeros(n_trials)\n",
    "res_mlp_X1_large = np.zeros(n_trials)\n",
    "res_ours = np.zeros(n_trials)\n",
    "res_test = np.zeros(n_trials)\n",
    "res_ours_oracle = np.zeros(n_trials)\n",
    "predict_mean = np.zeros(n_trials)\n",
    "predict_mean_large = np.zeros(n_trials)\n",
    "train_size_small = 300\n",
    "train_size_large = 3500\n",
    "for i in range(n_trials):\n",
    "    print(\"Trial\", i)\n",
    "    print(\"---------------\")\n",
    "    X1 = torch.randn(3000, 10)\n",
    "    X2 = torch.randn(3000, 11)\n",
    "    X3 = torch.randn(6000, 10)\n",
    "    # Create a random function with an MLP\n",
    "    #f = MLPDeep(n_layers=3, input_size=10, hidden_size=256, output_size=1, classif=False)\n",
    "    f = nn.Linear(10, 1)\n",
    "    f = f.to(device)\n",
    "    X1 = X1.to(device)\n",
    "    X2 = X2.to(device)\n",
    "    X3 = X3.to(device)\n",
    "    with torch.no_grad():\n",
    "        y = f(X1) + (torch.randn(X1.shape[0]).to(device) * 0.1).reshape(-1, 1)\n",
    "        X2[:, 10] = (f(X2[:, :10]) + (torch.randn(X2.shape[0]).to(device) * 0.1).reshape(-1, 1)).reshape(-1)\n",
    "        print(\"y\", y.shape)\n",
    "    #res_rf_X1[i] = compute_accuracy_rf(X1.detach(), y.detach(), train_size_small)\n",
    "    rf = RandomForestRegressor()\n",
    "    # split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1.detach().cpu(), y.detach().cpu(), train_size=train_size_small)\n",
    "    rf.fit(X_train, y_train)\n",
    "    res_rf_X1[i] = mean_squared_error(rf.predict(X_test), y_test)\n",
    "\n",
    "    # Find top 10 match in X2\n",
    "    y_pred = np.zeros(X1.shape[0])\n",
    "    for j in range(X1.shape[0]):\n",
    "        X2 = X2.cpu()\n",
    "        X1 = X1.cpu()\n",
    "        y_pred[j] = torch.mean(X2[:, 10][np.argsort(np.linalg.norm(X2[:, :10] - X1[j], axis=1))[:10]])\n",
    "    res_test[i] = mean_squared_error(y_pred, y.detach().cpu())\n",
    "\n",
    "\n",
    "    predictor, test_score = train_mlp(X1, y, 256, lr=0.001, n_epochs=60, dim_feedforward=32, n_train=train_size_small, train_prop=None)\n",
    "    res_mlp_X1[i] = test_score\n",
    "    with torch.no_grad():\n",
    "        y2 = f(X3) + (torch.randn(6000).to(device) * 0.1).reshape(-1, 1)\n",
    "    \n",
    "    rf = RandomForestRegressor()\n",
    "    # split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X3.detach().cpu(), y2.detach().cpu(), train_size=train_size_large)\n",
    "    rf.fit(X_train, y_train)\n",
    "    res_rf_X1_large[i] = mean_squared_error(rf.predict(X_test), y_test)\n",
    "\n",
    "\n",
    "    predictor, test_score = train_mlp(X3, y2, 256, lr=0.001, n_epochs=60, dim_feedforward=32, n_train=train_size_large, train_prop=None)\n",
    "    res_mlp_X1_large[i] = test_score\n",
    "\n",
    "    scorer = CustomModel(n_features=X1.shape[1], n_features_2=X2.shape[1], dim_feedforward=dim_feedforward)\n",
    "    scorer, predictor, test_score = train_matching(X1, X2, y, 256, scorer, preprocess=True, lr=0.001, n_epochs=60, dim_feedforward=32, n_train=train_size_small, train_prop=None)\n",
    "    res_ours[i] = test_score\n",
    "\n",
    "    scorer = OracleScorer(n_features=X1.shape[1], n_features_2=X2.shape[1], dim_feedforward=dim_feedforward)\n",
    "    scorer, predictor, test_score = train_matching(X1, X2, y, 256, scorer, preprocess=True, lr=0.001, n_epochs=60, dim_feedforward=32, n_train=train_size_small, train_prop=None)\n",
    "    res_ours_oracle[i] = test_score\n",
    "\n",
    "    # try to predict the mean\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1.detach().cpu(), y.detach().cpu(), train_size=train_size_small)\n",
    "    predict_mean[i] = mean_squared_error(torch.mean(y_train) * torch.ones(y_test.shape), y_test)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X3.detach().cpu(), y2.detach().cpu(), train_size=train_size_large)\n",
    "    print(torch.mean(y_train, dim=0) * torch.ones(y_test.shape))\n",
    "    predict_mean_large[i] = mean_squared_error(torch.mean(y_train, dim=0) * torch.ones(y_test.shape), y_test)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.boxplot([res_rf_X1, res_rf_X1_large, res_ours], labels=[\"RF on X1\", \"RF on X1 (large)\", \"Ours\"])\n",
    "# figsize=(10, 10)\n",
    "fig, ax = plt.subplots(figsize=(20, 7))\n",
    "plt.boxplot([res_rf_X1, res_mlp_X1, res_rf_X1_large, res_mlp_X1_large, res_test, predict_mean, predict_mean_large, res_ours, res_ours_oracle], labels=[f\"RF on {train_size_small} samples\", f\"MLP on  {train_size_small} samples\", f\"RF on {train_size_large} samples\", f\"MLP on {train_size_large} samples\", \"Test\", \"Predict mean\", \"Predict mean (large)\", \"Ours\", \"Ours (oracle)\"])\n",
    "#plt.boxplot([res_rf_X1, res_mlp_X1, res_rf_X1_large, res_mlp_X1_large, res_test, predict_mean, predict_mean_large], labels=[f\"RF on {train_size_small} samples\", f\"MLP on  {train_size_small} samples\", f\"RF on {train_size_large} samples\", f\"MLP on {train_size_large} samples\", \"Test\", \"Predict mean\", \"Predict mean (large)\"])\n",
    "plt.ylabel(\"Mean absolute error\")\n",
    "plt.yscale(\"log\")\n",
    "#plt.title(f\"Comparison of the different methods: X1 contains {X1.shape[0]} samples, X2 contains {X2.shape[0]} samples.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match indices of dataset1 and dataset2 on the first coordinate\n",
    "distance = torch.cdist(dataset1[:, 0].reshape(-1, 1), dataset2[:, 0].reshape(-1, 1))\n",
    "# replace the 2nd coordinate of dataset1 by the 2nd coordinate of dataset2\n",
    "dataset1_copy = dataset1.clone()\n",
    "dataset1_copy[:, 1] = torch.sum(dataset2[distance.argmin(dim=1)], dim=1)\n",
    "\n",
    "\n",
    "print(\"-- Random Forest --\")\n",
    "print(\"Accuracy with dataset1\", compute_accuracy_rf(dataset1_copy, y, 1000))\n",
    "print(\"Accuracy with dataset2\", compute_accuracy_rf(dataset2, y, 1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-- TabPFN original --\")\n",
    "print(\"Accuracy with dataset1\", compute_accuracy_tabpfn_original(dataset1, y, 1000))\n",
    "#print(\"Accuracy with dataset2\", compute_accuracy_tabpfn_original(dataset2, y, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-- TabPFN --\")\n",
    "print(\"Without preprocessing\")\n",
    "print(\"Accuracy with dataset1\", compute_accuracy_tabpfn(dataset1, y, 1000, preprocess=False))\n",
    "print(\"Accuracy with dataset2\", compute_accuracy_tabpfn(dataset2, y, 1000, preprocess=False))\n",
    "print(\"With preprocessing\")\n",
    "print(\"Accuracy with dataset1\", compute_accuracy_tabpfn(dataset1, y, 1000, preprocess=True))\n",
    "print(\"Accuracy with dataset2\", compute_accuracy_tabpfn(dataset2, y, 1000, preprocess=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_attention(module, dataset1, dataset2, y, 1000, preprocess=True, lr=0.001, n_epochs=1000, train_tabpfn=False)\n",
    "train_matching(dataset1, dataset2, y, 256, preprocess=True, lr=0.001, n_epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "model = TabPFNClassifier(device=device)\n",
    "\n",
    "module = model.model[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the same thing on the california housing dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_california = data[\"frame\"]\n",
    "# drop the target\n",
    "df_california = df_california.drop(\"MedHouseVal\", axis=1)\n",
    "# drop income\n",
    "df_california_without_income = df_california.drop(\"MedInc\", axis=1)\n",
    "# Drop more columns to make it harder\n",
    "# df_california = df_california.drop(\"AveOccup\", axis=1)\n",
    "# df_california_without_income = df_california_without_income.drop(\"AveOccup\", axis=1)\n",
    "# only keep Latitude and Longitude\n",
    "df_california = df_california[[\"MedInc\", \"Latitude\", \"Longitude\"]]\n",
    "df_california_without_income = df_california_without_income[[\"Latitude\", \"Longitude\"]]\n",
    "target = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_california"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'City': ['Los Angeles', 'San Diego', 'San Jose', 'San Francisco', 'Fresno', 'Sacramento', 'Long Beach', 'Oakland', 'Bakersfield', 'Anaheim', 'Santa Ana', 'Riverside', 'Stockton', 'Chula Vista', 'Irvine', 'Fremont', 'San Bernardino', 'Modesto', 'Fontana', 'Oxnard'], \n",
    "        'Average Household Income': ['$101,006', '$113,681', '$150,601', '$167,663', '$73,396', '$87,213', '$89,912', '$116,585', '$84,592', '$97,136', '$88,829', '$90,520', '$78,712', '$105,155', '$140,764', '$170,083', '$64,929', '$81,841', '$93,383', '$91,636']}\n",
    "\n",
    "df_cities = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lat and long for each city\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"my-application (leo.grinsztajn@gmail.com)\")\n",
    "df_cities[\"location\"] = df_cities[\"City\"].apply(lambda x: geolocator.geocode(x))\n",
    "df_cities[\"latitude\"] = df_cities[\"location\"].apply(lambda x: x.latitude)\n",
    "df_cities[\"longitude\"] = df_cities[\"location\"].apply(lambda x: x.longitude)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target to a classification problem\n",
    "target_classif = (target > np.median(target)).astype(int)\n",
    "\n",
    "# Convert df_california to a torch tensor\n",
    "california_tensor = torch.tensor(df_california.values).float()\n",
    "california_without_income_tensor = torch.tensor(df_california_without_income.values).float()\n",
    "target_tensor = torch.tensor(target_classif.values).float()\n",
    "\n",
    "# Suffle the data\n",
    "from sklearn.utils import shuffle\n",
    "california_tensor, california_without_income_tensor, target_tensor = shuffle(california_tensor, california_without_income_tensor, target_tensor, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "california_tensor = california_tensor.reshape(california_tensor.shape[0], 1, california_tensor.shape[1])\n",
    "california_without_income_tensor = california_without_income_tensor.reshape(california_without_income_tensor.shape[0], 1, california_without_income_tensor.shape[1])\n",
    "target_tensor = target_tensor.reshape(target.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate the first dim to 5000\n",
    "california_tensor = california_tensor[:5000]\n",
    "california_without_income_tensor = california_without_income_tensor[:5000]\n",
    "target_tensor = target_tensor[:5000]\n",
    "\n",
    "print(np.unique(target_tensor, return_counts=True))\n",
    "# print proportion of 1\n",
    "p = np.unique(target_tensor, return_counts=True)[1][1] / np.unique(target_tensor, return_counts=True)[1].sum()\n",
    "print(p)\n",
    "print(1-p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(california_tensor.shape)\n",
    "print(california_without_income_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU\n",
    "california_tensor = california_tensor.to(device)\n",
    "california_without_income_tensor = california_without_income_tensor.to(device)\n",
    "target_tensor = target_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = TabPFNClassifier(N_ensemble_configurations=1, feature_shift_decoder=False)\n",
    "\n",
    "#module = model.model[2]\n",
    "# Pad with 0s until we have 100 features\n",
    "\n",
    "n_samples, n_features = california_tensor.shape[0], california_tensor.shape[2]\n",
    "model.fit(california_tensor[:1000].reshape(1000, n_features).cpu(), target_tensor[:1000].reshape(1000).cpu())\n",
    "y_pred = model.predict(california_tensor[1000:].reshape(4000, n_features).cpu())\n",
    "print(\"Accuracy with income\")\n",
    "print(accuracy_score(target_tensor[1000:].reshape(-1).cpu(), y_pred))\n",
    "\n",
    "n_samples, n_features = california_without_income_tensor.shape[0], california_without_income_tensor.shape[2]\n",
    "model.fit(california_without_income_tensor[:1000].reshape(1000, n_features).cpu(), target_tensor[:1000].reshape(1000).cpu())\n",
    "y_pred = model.predict(california_without_income_tensor[1000:].reshape(4000, n_features).cpu())\n",
    "print(\"Accuracy without income\")\n",
    "print(accuracy_score(target_tensor[1000:].reshape(-1).cpu(), y_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer\n",
    "#TODO why the difference with random forest?\n",
    "#scaler = StandardScaler()\n",
    "#california_tensor_processed = torch.tensor(scaler.fit_transform(california_tensor.reshape(-1, california_tensor.shape[-1])).reshape(california_tensor.shape))\n",
    "#california_without_income_tensor_processed = torch.tensor(scaler.fit_transform(california_without_income_tensor.reshape(-1, california_without_income_tensor.shape[-1])).reshape(california_without_income_tensor.shape))\n",
    "print(california_tensor.shape)\n",
    "california_tensor_processed = preprocess_input(california_tensor, target_tensor, [], preprocess_transform='power')\n",
    "california_without_income_tensor_processed = preprocess_input(california_without_income_tensor, target_tensor, [], preprocess_transform='power')\n",
    "# Pad last dimension with 0 to 100\n",
    "california_tensor_processed = torch.nn.functional.pad(california_tensor_processed, (0, 100-california_tensor.shape[2]))\n",
    "california_without_income_tensor_processed = torch.nn.functional.pad(california_without_income_tensor_processed, (0, 100-california_without_income_tensor.shape[2]))\n",
    "print(california_tensor_processed.shape)\n",
    "# convert to float\n",
    "california_tensor_processed = california_tensor_processed.float()\n",
    "y_pred = torch.argmax(module((california_tensor_processed, target_tensor), single_eval_pos=1000, x_already_encoded=False), dim=-1).reshape(-1)\n",
    "california_without_income_tensor_processed = california_without_income_tensor_processed.float()\n",
    "y_pred2 = torch.argmax(module((california_without_income_tensor_processed, target_tensor), single_eval_pos=1000, x_already_encoded=False), dim=-1).reshape(-1)\n",
    "# print shapes\n",
    "print(y_pred.shape)\n",
    "print(y_pred2.shape)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy with income\")\n",
    "print(accuracy_score(target_tensor[-len(y_pred):].cpu(), y_pred.cpu()))\n",
    "print(\"Accuracy without income\")\n",
    "print(accuracy_score(target_tensor[-len(y_pred2):].cpu(), y_pred2.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with a random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "X, y = california_tensor.reshape(california_tensor.shape[0], -1).cpu().numpy(), target_tensor.reshape(-1).cpu().numpy()\n",
    "# The train part is the first 1000 samples\n",
    "rf.fit(X[:1000], y[:1000])\n",
    "y_pred = rf.predict(X[1000:])\n",
    "print(\"Accuracy with income\")\n",
    "print(accuracy_score(y[1000:], y_pred))\n",
    "\n",
    "# without income\n",
    "rf = RandomForestClassifier()\n",
    "X, y = california_without_income_tensor.reshape(california_without_income_tensor.shape[0], -1).cpu().numpy(), target_tensor.reshape(-1).cpu().numpy()\n",
    "# The train part is the first 1000 samples\n",
    "rf.fit(X[:1000], y[:1000])\n",
    "y_pred = rf.predict(X[1000:])\n",
    "print(\"Accuracy without income\")\n",
    "print(accuracy_score(y[1000:], y_pred))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert value like $101,006' to 101006\n",
    "df_cities[\"Average Household Income\"] = df_cities[\"Average Household Income\"].apply(lambda x: int(x.replace(\"$\", \"\").replace(\",\", \"\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df_cities to a torch tensor\n",
    "cities_tensor = torch.tensor(df_cities[[\"Average Household Income\", \"latitude\", \"longitude\"]].values).float()\n",
    "# Reshape\n",
    "cities_tensor = cities_tensor.reshape(cities_tensor.shape[0], 1, cities_tensor.shape[1])\n",
    "\n",
    "# preporcess the data\n",
    "#cities_tensor_processed = preprocess_input(cities_tensor, target_tensor, [], preprocess_transform='power')\n",
    "#cities_tensor_processed = cities_tensor\n",
    "# Use a standard scaler\n",
    "scaler = StandardScaler()\n",
    "cities_tensor_processed = torch.tensor(scaler.fit_transform(cities_tensor.reshape(-1, cities_tensor.shape[-1])).reshape(cities_tensor.shape))\n",
    "# convert to float\n",
    "cities_tensor_processed = cities_tensor_processed.float()\n",
    "\n",
    "# Pad last dimension with 0 to 100\n",
    "#TODO: think, do I need to do this or can I just put the vector in the attention?\n",
    "cities_tensor_processed = torch.nn.functional.pad(cities_tensor_processed, (0, 100-cities_tensor.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to GPU\n",
    "cities_tensor_processed = cities_tensor_processed.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multihead attention\n",
    "from torch.nn import MultiheadAttention\n",
    "n = 512\n",
    "attention = MultiheadAttention(embed_dim=n, num_heads=1, dropout=0.0, device=device)\n",
    "W_q = torch.rand(n, n).to(device)\n",
    "W_k = torch.rand(n, n).to(device)\n",
    "W_v = torch.rand(n, n).to(device)\n",
    "W_q.requires_grad = True\n",
    "W_k.requires_grad = True\n",
    "W_v.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000\n",
    "val_size = 2000\n",
    "test_size = 2000\n",
    "\n",
    "assert train_size + val_size + test_size == len(california_tensor_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suffle the \"Average Household Income\" column\n",
    "cities_tensor_processed_random = cities_tensor_processed[torch.randperm(cities_tensor_processed.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the attention matrix W_q, W_k, W_v\n",
    "#TODO: check if we train on test\n",
    "from torch import optim\n",
    "optimizer = optim.Adam([W_q, W_k, W_v], lr=0.01)\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    input = model.model[2].encoder(california_without_income_tensor_processed)\n",
    "    input2 = model.model[2].encoder(cities_tensor_processed)\n",
    "    Q = torch.matmul(input, W_q)\n",
    "    K = torch.matmul(input2, W_k)\n",
    "    V = torch.matmul(input2, W_v)\n",
    "    full_input = input + attention(Q, K, V)[0]\n",
    "    y_pred = module((full_input, target_tensor), single_eval_pos=train_size, x_already_encoded=True).squeeze()\n",
    "    loss = torch.nn.functional.cross_entropy(y_pred[:val_size], target_tensor[-len(y_pred):-len(y_pred) + val_size].squeeze().long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    if i % 10 == 0:\n",
    "        y_pred = torch.argmax(y_pred, dim=-1).reshape(-1)\n",
    "        print(accuracy_score(target_tensor[-len(y_pred) + val_size:].cpu(), y_pred[val_size:].cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: GPU and correct scoring of baselinees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tab_pfn2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21dbb7094b1385f0bae0b91ae49063169e8dea4181459eda714e1f1fb7500475"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
