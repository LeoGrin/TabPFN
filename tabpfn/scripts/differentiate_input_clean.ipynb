{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' from '/home/parietal/lgrinszt/.local/miniconda3/envs/tab_pfn2/lib/python3.9/site-packages/wandb/__init__.py'>\n",
      "Using cuda:0 device\n",
      "Batch size: 1\n",
      "Using distributed training: False\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    }
   ],
   "source": [
    "from tabpfn.scripts.transformer_prediction_interface import TabPFNClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, PowerTransformer, RobustScaler\n",
    "import torch\n",
    "from torch.nn import MultiheadAttention\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "model = TabPFNClassifier(device=device)\n",
    "module = model.model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn.utils import normalize_data, to_ranking_low_mem, remove_outliers\n",
    "from tabpfn.priors.utils import normalize_by_used_features_f\n",
    "\n",
    "normalize_with_test = True #TODO change\n",
    "#eval_position = 100\n",
    "normalize_to_ranking = False\n",
    "max_features=100\n",
    "normalize_with_sqrt = False\n",
    "\n",
    "def preprocess_input(eval_xs, eval_ys, categorical_feats, preprocess_transform):\n",
    "    import warnings\n",
    "\n",
    "    if eval_xs.shape[1] > 1:\n",
    "        raise Exception(\"Transforms only allow one batch dim - TODO\")\n",
    "    if preprocess_transform != 'none':\n",
    "        if preprocess_transform == 'power' or preprocess_transform == 'power_all':\n",
    "            pt = PowerTransformer(standardize=True)\n",
    "        elif preprocess_transform == 'quantile' or preprocess_transform == 'quantile_all':\n",
    "            pt = QuantileTransformer(output_distribution='normal')\n",
    "        elif preprocess_transform == 'robust' or preprocess_transform == 'robust_all':\n",
    "            pt = RobustScaler(unit_variance=True)\n",
    "\n",
    "    # eval_xs, eval_ys = normalize_data(eval_xs), normalize_data(eval_ys)\n",
    "    eval_xs = normalize_data(eval_xs, normalize_positions=-1 if normalize_with_test else eval_position)\n",
    "\n",
    "    # Removing empty features\n",
    "    eval_xs = eval_xs[:, 0, :]\n",
    "    sel = [len(torch.unique(eval_xs[0:eval_ys.shape[0], col])) > 1 for col in range(eval_xs.shape[1])]\n",
    "    eval_xs = eval_xs[:, sel]\n",
    "\n",
    "    warnings.simplefilter('error')\n",
    "    if preprocess_transform != 'none':\n",
    "        eval_xs = eval_xs.cpu().numpy()\n",
    "        feats = set(range(eval_xs.shape[1])) if 'all' in preprocess_transform else set(\n",
    "            range(eval_xs.shape[1])) - set(categorical_feats)\n",
    "        for col in feats:\n",
    "            try:\n",
    "                pt.fit(eval_xs[0:eval_position, col:col + 1])\n",
    "                trans = pt.transform(eval_xs[:, col:col + 1])\n",
    "                # print(scipy.stats.spearmanr(trans[~np.isnan(eval_xs[:, col:col+1])], eval_xs[:, col:col+1][~np.isnan(eval_xs[:, col:col+1])]))\n",
    "                eval_xs[:, col:col + 1] = trans\n",
    "            except:\n",
    "                pass\n",
    "        eval_xs = torch.tensor(eval_xs).float()\n",
    "    warnings.simplefilter('default')\n",
    "\n",
    "    eval_xs = eval_xs.unsqueeze(1)\n",
    "\n",
    "    # TODO: Cautian there is information leakage when to_ranking is used, we should not use it\n",
    "    eval_xs = remove_outliers(eval_xs, normalize_positions=-1 if normalize_with_test else eval_position) if not normalize_to_ranking else normalize_data(to_ranking_low_mem(eval_xs))\n",
    "    # Rescale X\n",
    "    eval_xs = normalize_by_used_features_f(eval_xs, eval_xs.shape[-1], max_features,\n",
    "                                            normalize_with_sqrt=normalize_with_sqrt)\n",
    "\n",
    "    return eval_xs.detach().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_rf(X, y, n_train):\n",
    "    # Move X and y to CPU\n",
    "    X = X.to(\"cpu\")\n",
    "    y = y.to(\"cpu\")\n",
    "    rf = RandomForestClassifier()\n",
    "    X_train, X_test = X[:n_train], X[n_train:]\n",
    "    y_train, y_test = y[:n_train], y[n_train:]\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def compute_accuracy_tabpfn_original(X, y, n_train):\n",
    "    X = X.to(\"cpu\") #FIXME\n",
    "    y = y.to(\"cpu\")\n",
    "    X_train, X_test = X[:n_train], X[n_train:]\n",
    "    y_train, y_test = y[:n_train], y[n_train:]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def compute_accuracy_tabpfn(X, y, n_train, preprocess=False):\n",
    "    # reshape X to be 3D\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    # reshape y to be 2D\n",
    "    y = y.reshape(y.shape[0], 1)\n",
    "    if preprocess:\n",
    "        X = preprocess_input(X, y, [], 'power')\n",
    "    X = X.to(device)\n",
    "    y_pred = torch.argmax(module((X, y), single_eval_pos=n_train, x_already_encoded=False), dim=-1).reshape(-1)\n",
    "    # Check the accuracy\n",
    "    print(accuracy_score(y[-len(y_pred):].cpu(), y_pred.cpu())) #FIXME\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_attention(module, X1, X2, y, n_train, preprocess=False, lr=0.01, n_epochs=100, train_tabpfn=False):\n",
    "    # reshape X to be 3D\n",
    "    X1 = X1.reshape(X1.shape[0], 1, X1.shape[1])\n",
    "    X2 = X2.reshape(X2.shape[0], 1, X2.shape[1])\n",
    "    # reshape y to be 2D\n",
    "    y = y.reshape(y.shape[0], 1)\n",
    "    if preprocess:\n",
    "        X1 = preprocess_input(X1, y, [], 'power')\n",
    "        X2 = preprocess_input(X2, y, [], 'power')\n",
    "\n",
    "    n = 512 # to be compatible with pretrained TabPFN\n",
    "    attention = MultiheadAttention(embed_dim=n, num_heads=1, dropout=0.0, device=device)\n",
    "    W_q = nn.Linear(n, n).to(device)\n",
    "    W_k = nn.Linear(n, n).to(device)\n",
    "    W_v = nn.Linear(n, n).to(device)\n",
    "    #W_o = nn.Linear(n, 2).to(device)\n",
    "    W_q.requires_grad = True\n",
    "    W_k.requires_grad = True\n",
    "    W_v.requires_grad = True\n",
    "    #W_o.requires_grad = True\n",
    "    train_size = n_train\n",
    "    #TODO think about this. Do I really need a train set?\n",
    "    val_size = (len(X1) - train_size) // 2\n",
    "    test_size = len(X1) - train_size - val_size\n",
    "    if train_tabpfn:\n",
    "        optimizer = optim.Adam([*W_q.parameters(), *W_k.parameters(), *W_v.parameters(), *module.parameters()], lr=lr)\n",
    "    else:\n",
    "        optimizer = optim.Adam([*W_q.parameters(), *W_k.parameters(), *W_v.parameters()], lr=lr)\n",
    "        with torch.no_grad():\n",
    "            input = module.encoder(X1)\n",
    "            input2 = module.encoder(X2)\n",
    "    for i in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        if train_tabpfn:\n",
    "            input = module.encoder(X1)\n",
    "            input2 = module.encoder(X2)\n",
    "        Q = W_q(input)\n",
    "        K = W_k(input2)\n",
    "        V = W_v(input2)\n",
    "        #full_input = input + attention(Q, K, V)[0]\n",
    "        full_input = input + attention(Q, K, V)[0]\n",
    "        y_pred = module((full_input, y), single_eval_pos=train_size, x_already_encoded=True).squeeze()\n",
    "        #y_pred = W_o(full_input).squeeze()\n",
    "        loss = torch.nn.functional.cross_entropy(y_pred[:val_size], y[-len(y_pred):-len(y_pred) + val_size].squeeze().long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 2 == 0:\n",
    "            print(loss)\n",
    "        if i % 10 == 0:\n",
    "            y_pred = torch.argmax(y_pred, dim=-1).reshape(-1)\n",
    "            print(\"Test accuracy:\")\n",
    "            print(\"Number of test samples: \", test_size)\n",
    "            print(accuracy_score(y[-len(y_pred) + val_size:].cpu(), y_pred[val_size:].cpu()))\n",
    "            print(\"Train accuracy:\")\n",
    "            #print(\"Number of train samples: \", train_size)\n",
    "            #print(accuracy_score(y[:train_size].cpu(), y_pred[:train_size].cpu()))\n",
    "            print(\"Val accuracy:\")\n",
    "            print(\"Number of val samples: \", val_size)\n",
    "            print(accuracy_score(y[-len(y_pred):-len(y_pred) + val_size].cpu(), y_pred[:val_size].cpu()))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a non linear function\n",
    "#f = torch.functional.F.relu\n",
    "f = lambda x: x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1.], dtype=float32), array([10000, 10000]))\n"
     ]
    }
   ],
   "source": [
    "# Create fake datasets\n",
    "# Create a first dataset with columns A, B\n",
    "torch.manual_seed(40)\n",
    "dataset1 = torch.rand(20000, 100)\n",
    "# Create a second dataset with columns C, D\n",
    "dataset2 = torch.rand(20000, 100)\n",
    "\n",
    "# Make column C equal to column A * 2 + noise\n",
    "dataset2[:, 0] = dataset1[:, 0]# * 2 #+ torch.rand(1000) * 0.1\n",
    "\n",
    "# Create y as D + noise\n",
    "#y = torch.sum(dataset2, dim=1)# + f(dataset1[:, 4]) #+ torch.rand(1000) * 0.1\n",
    "#with torch.no_grad():\n",
    "#    y = torch.sum(module.encoder(dataset2.reshape(dataset2.shape[0], 1, dataset2.shape[1]).to(device)).reshape(dataset2.shape[0], -1), dim=1).cpu()\n",
    "y = dataset2[:, 1]\n",
    "\n",
    "#dataset2.requires_grad = True\n",
    "#dataset1.requires_grad = True\n",
    "\n",
    "# Make it a classification problem\n",
    "y = (y > np.median(y)).float()\n",
    "\n",
    "print(np.unique(y, return_counts=True))\n",
    "\n",
    "# Move to GPU\n",
    "dataset1 = dataset1.to(device)\n",
    "dataset2 = dataset2.to(device)\n",
    "y = y.to(device)\n",
    "# Shuffle dataset2\n",
    "dataset2 = dataset2[torch.randperm(len(dataset2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Random Forest --\n",
      "Accuracy with dataset1 0.5012631578947369\n",
      "Accuracy with dataset2 0.4998947368421053\n",
      "Accuracy with dataset1 + dataset2 0.4986315789473684\n"
     ]
    }
   ],
   "source": [
    "print(\"-- Random Forest --\")\n",
    "print(\"Accuracy with dataset1\", compute_accuracy_rf(dataset1, y, 1000))\n",
    "print(\"Accuracy with dataset2\", compute_accuracy_rf(dataset2, y, 1000))\n",
    "print(\"Accuracy with dataset1 + dataset2\", compute_accuracy_rf(torch.cat((dataset1, dataset2), dim=1), y, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Random Forest --\n",
      "Accuracy with dataset1 0.4996842105263158\n",
      "Accuracy with dataset2 0.49857894736842107\n"
     ]
    }
   ],
   "source": [
    "# match indices of dataset1 and dataset2 on the first coordinate\n",
    "distance = torch.cdist(dataset1[:, 0].reshape(-1, 1), dataset2[:, 0].reshape(-1, 1))\n",
    "# replace the 2nd coordinate of dataset1 by the 2nd coordinate of dataset2\n",
    "dataset1_copy = dataset1.clone()\n",
    "dataset1_copy[:, 1] = torch.sum(dataset2[distance.argmin(dim=1)], dim=1)\n",
    "\n",
    "\n",
    "print(\"-- Random Forest --\")\n",
    "print(\"Accuracy with dataset1\", compute_accuracy_rf(dataset1_copy, y, 1000))\n",
    "print(\"Accuracy with dataset2\", compute_accuracy_rf(dataset2, y, 1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TabPFN original --\n",
      "interface\n",
      "torch.Size([20000, 1, 100])\n",
      "torch.Size([20000, 1])\n",
      "1000\n",
      "Accuracy with dataset1 0.4996315789473684\n",
      "interface\n",
      "torch.Size([20000, 1, 100])\n",
      "torch.Size([20000, 1])\n",
      "1000\n",
      "Accuracy with dataset2 0.5006315789473684\n"
     ]
    }
   ],
   "source": [
    "print(\"-- TabPFN original --\")\n",
    "print(\"Accuracy with dataset1\", compute_accuracy_tabpfn_original(dataset1, y, 1000))\n",
    "print(\"Accuracy with dataset2\", compute_accuracy_tabpfn_original(dataset2, y, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TabPFN --\n",
      "Without preprocessing\n",
      "0.496\n",
      "Accuracy with dataset1 None\n",
      "0.5008947368421053\n",
      "Accuracy with dataset2 None\n",
      "With preprocessing\n",
      "0.4991052631578947\n",
      "Accuracy with dataset1 None\n",
      "0.4993684210526316\n",
      "Accuracy with dataset2 None\n"
     ]
    }
   ],
   "source": [
    "print(\"-- TabPFN --\")\n",
    "print(\"Without preprocessing\")\n",
    "print(\"Accuracy with dataset1\", compute_accuracy_tabpfn(dataset1, y, 1000, preprocess=False))\n",
    "print(\"Accuracy with dataset2\", compute_accuracy_tabpfn(dataset2, y, 1000, preprocess=False))\n",
    "print(\"With preprocessing\")\n",
    "print(\"Accuracy with dataset1\", compute_accuracy_tabpfn(dataset1, y, 1000, preprocess=True))\n",
    "print(\"Accuracy with dataset2\", compute_accuracy_tabpfn(dataset2, y, 1000, preprocess=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test accuracy:\n",
      "Number of test samples:  9500\n",
      "0.4985263157894737\n",
      "Train accuracy:\n",
      "Val accuracy:\n",
      "Number of val samples:  9500\n",
      "0.5025263157894737\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "train_attention(module, dataset1, dataset2, y, 1000, preprocess=True, lr=0.001, n_epochs=1000, train_tabpfn=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' from '/home/parietal/lgrinszt/.local/miniconda3/envs/tab_pfn2/lib/python3.9/site-packages/wandb/__init__.py'>\n",
      "Using cuda:0 device\n",
      "Batch size: 1\n",
      "Using distributed training: False\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "model = TabPFNClassifier(device=device)\n",
    "\n",
    "module = model.model[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the same thing on the california housing dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_california = data[\"frame\"]\n",
    "# drop the target\n",
    "df_california = df_california.drop(\"MedHouseVal\", axis=1)\n",
    "# drop income\n",
    "df_california_without_income = df_california.drop(\"MedInc\", axis=1)\n",
    "# Drop more columns to make it harder\n",
    "# df_california = df_california.drop(\"AveOccup\", axis=1)\n",
    "# df_california_without_income = df_california_without_income.drop(\"AveOccup\", axis=1)\n",
    "# only keep Latitude and Longitude\n",
    "df_california = df_california[[\"MedInc\", \"Latitude\", \"Longitude\"]]\n",
    "df_california_without_income = df_california_without_income[[\"Latitude\", \"Longitude\"]]\n",
    "target = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  Latitude  Longitude\n",
       "0      8.3252     37.88    -122.23\n",
       "1      8.3014     37.86    -122.22\n",
       "2      7.2574     37.85    -122.24\n",
       "3      5.6431     37.85    -122.25\n",
       "4      3.8462     37.85    -122.25\n",
       "...       ...       ...        ...\n",
       "20635  1.5603     39.48    -121.09\n",
       "20636  2.5568     39.49    -121.21\n",
       "20637  1.7000     39.43    -121.22\n",
       "20638  1.8672     39.43    -121.32\n",
       "20639  2.3886     39.37    -121.24\n",
       "\n",
       "[20640 rows x 3 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_california"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'City': ['Los Angeles', 'San Diego', 'San Jose', 'San Francisco', 'Fresno', 'Sacramento', 'Long Beach', 'Oakland', 'Bakersfield', 'Anaheim', 'Santa Ana', 'Riverside', 'Stockton', 'Chula Vista', 'Irvine', 'Fremont', 'San Bernardino', 'Modesto', 'Fontana', 'Oxnard'], \n",
    "        'Average Household Income': ['$101,006', '$113,681', '$150,601', '$167,663', '$73,396', '$87,213', '$89,912', '$116,585', '$84,592', '$97,136', '$88,829', '$90,520', '$78,712', '$105,155', '$140,764', '$170,083', '$64,929', '$81,841', '$93,383', '$91,636']}\n",
    "\n",
    "df_cities = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lat and long for each city\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"my-application (leo.grinsztajn@gmail.com)\")\n",
    "df_cities[\"location\"] = df_cities[\"City\"].apply(lambda x: geolocator.geocode(x))\n",
    "df_cities[\"latitude\"] = df_cities[\"location\"].apply(lambda x: x.latitude)\n",
    "df_cities[\"longitude\"] = df_cities[\"location\"].apply(lambda x: x.longitude)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Convert target to a classification problem\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m target_classif \u001b[39m=\u001b[39m (target \u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mmedian(target))\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Convert df_california to a torch tensor\u001b[39;00m\n\u001b[1;32m      5\u001b[0m california_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(df_california\u001b[39m.\u001b[39mvalues)\u001b[39m.\u001b[39mfloat()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert target to a classification problem\n",
    "target_classif = (target > np.median(target)).astype(int)\n",
    "\n",
    "# Convert df_california to a torch tensor\n",
    "california_tensor = torch.tensor(df_california.values).float()\n",
    "california_without_income_tensor = torch.tensor(df_california_without_income.values).float()\n",
    "target_tensor = torch.tensor(target_classif.values).float()\n",
    "\n",
    "# Suffle the data\n",
    "from sklearn.utils import shuffle\n",
    "california_tensor, california_without_income_tensor, target_tensor = shuffle(california_tensor, california_without_income_tensor, target_tensor, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "california_tensor = california_tensor.reshape(california_tensor.shape[0], 1, california_tensor.shape[1])\n",
    "california_without_income_tensor = california_without_income_tensor.reshape(california_without_income_tensor.shape[0], 1, california_without_income_tensor.shape[1])\n",
    "target_tensor = target_tensor.reshape(target.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1.], dtype=float32), array([2549, 2451]))\n",
      "0.4902\n",
      "0.5098\n"
     ]
    }
   ],
   "source": [
    "# Truncate the first dim to 5000\n",
    "california_tensor = california_tensor[:5000]\n",
    "california_without_income_tensor = california_without_income_tensor[:5000]\n",
    "target_tensor = target_tensor[:5000]\n",
    "\n",
    "print(np.unique(target_tensor, return_counts=True))\n",
    "# print proportion of 1\n",
    "p = np.unique(target_tensor, return_counts=True)[1][1] / np.unique(target_tensor, return_counts=True)[1].sum()\n",
    "print(p)\n",
    "print(1-p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 1, 3])\n",
      "torch.Size([5000, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(california_tensor.shape)\n",
    "print(california_without_income_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU\n",
    "california_tensor = california_tensor.to(device)\n",
    "california_without_income_tensor = california_without_income_tensor.to(device)\n",
    "target_tensor = target_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interface\n",
      "torch.Size([5000, 1, 3])\n",
      "torch.Size([5000, 1])\n",
      "1000\n",
      "src_mask None\n",
      "Accuracy with income\n",
      "0.8215\n",
      "interface\n",
      "torch.Size([5000, 1, 2])\n",
      "torch.Size([5000, 1])\n",
      "1000\n",
      "src_mask None\n",
      "Accuracy without income\n",
      "0.77825\n"
     ]
    }
   ],
   "source": [
    "#model = TabPFNClassifier(N_ensemble_configurations=1, feature_shift_decoder=False)\n",
    "\n",
    "#module = model.model[2]\n",
    "# Pad with 0s until we have 100 features\n",
    "\n",
    "n_samples, n_features = california_tensor.shape[0], california_tensor.shape[2]\n",
    "model.fit(california_tensor[:1000].reshape(1000, n_features).cpu(), target_tensor[:1000].reshape(1000).cpu())\n",
    "y_pred = model.predict(california_tensor[1000:].reshape(4000, n_features).cpu())\n",
    "print(\"Accuracy with income\")\n",
    "print(accuracy_score(target_tensor[1000:].reshape(-1).cpu(), y_pred))\n",
    "\n",
    "n_samples, n_features = california_without_income_tensor.shape[0], california_without_income_tensor.shape[2]\n",
    "model.fit(california_without_income_tensor[:1000].reshape(1000, n_features).cpu(), target_tensor[:1000].reshape(1000).cpu())\n",
    "y_pred = model.predict(california_without_income_tensor[1000:].reshape(4000, n_features).cpu())\n",
    "print(\"Accuracy without income\")\n",
    "print(accuracy_score(target_tensor[1000:].reshape(-1).cpu(), y_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 1, 3])\n",
      "torch.Size([5000, 1, 100])\n",
      "src_mask None\n",
      "src_mask None\n",
      "torch.Size([4000])\n",
      "torch.Size([4000])\n",
      "Accuracy with income\n",
      "0.822\n",
      "Accuracy without income\n",
      "0.783\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer\n",
    "#TODO why the difference with random forest?\n",
    "#scaler = StandardScaler()\n",
    "#california_tensor_processed = torch.tensor(scaler.fit_transform(california_tensor.reshape(-1, california_tensor.shape[-1])).reshape(california_tensor.shape))\n",
    "#california_without_income_tensor_processed = torch.tensor(scaler.fit_transform(california_without_income_tensor.reshape(-1, california_without_income_tensor.shape[-1])).reshape(california_without_income_tensor.shape))\n",
    "print(california_tensor.shape)\n",
    "california_tensor_processed = preprocess_input(california_tensor, target_tensor, [], preprocess_transform='power')\n",
    "california_without_income_tensor_processed = preprocess_input(california_without_income_tensor, target_tensor, [], preprocess_transform='power')\n",
    "# Pad last dimension with 0 to 100\n",
    "california_tensor_processed = torch.nn.functional.pad(california_tensor_processed, (0, 100-california_tensor.shape[2]))\n",
    "california_without_income_tensor_processed = torch.nn.functional.pad(california_without_income_tensor_processed, (0, 100-california_without_income_tensor.shape[2]))\n",
    "print(california_tensor_processed.shape)\n",
    "# convert to float\n",
    "california_tensor_processed = california_tensor_processed.float()\n",
    "y_pred = torch.argmax(module((california_tensor_processed, target_tensor), single_eval_pos=1000, x_already_encoded=False), dim=-1).reshape(-1)\n",
    "california_without_income_tensor_processed = california_without_income_tensor_processed.float()\n",
    "y_pred2 = torch.argmax(module((california_without_income_tensor_processed, target_tensor), single_eval_pos=1000, x_already_encoded=False), dim=-1).reshape(-1)\n",
    "# print shapes\n",
    "print(y_pred.shape)\n",
    "print(y_pred2.shape)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy with income\")\n",
    "print(accuracy_score(target_tensor[-len(y_pred):].cpu(), y_pred.cpu()))\n",
    "print(\"Accuracy without income\")\n",
    "print(accuracy_score(target_tensor[-len(y_pred2):].cpu(), y_pred2.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with income\n",
      "0.84425\n",
      "Accuracy without income\n",
      "0.835\n"
     ]
    }
   ],
   "source": [
    "# Try with a random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "X, y = california_tensor.reshape(california_tensor.shape[0], -1).cpu().numpy(), target_tensor.reshape(-1).cpu().numpy()\n",
    "# The train part is the first 1000 samples\n",
    "rf.fit(X[:1000], y[:1000])\n",
    "y_pred = rf.predict(X[1000:])\n",
    "print(\"Accuracy with income\")\n",
    "print(accuracy_score(y[1000:], y_pred))\n",
    "\n",
    "# without income\n",
    "rf = RandomForestClassifier()\n",
    "X, y = california_without_income_tensor.reshape(california_without_income_tensor.shape[0], -1).cpu().numpy(), target_tensor.reshape(-1).cpu().numpy()\n",
    "# The train part is the first 1000 samples\n",
    "rf.fit(X[:1000], y[:1000])\n",
    "y_pred = rf.predict(X[1000:])\n",
    "print(\"Accuracy without income\")\n",
    "print(accuracy_score(y[1000:], y_pred))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Average Household Income</th>\n",
       "      <th>location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>$101,006</td>\n",
       "      <td>(Los Angeles, Los Angeles County, CAL Fire Con...</td>\n",
       "      <td>34.053691</td>\n",
       "      <td>-118.242766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>$113,681</td>\n",
       "      <td>(San Diego, San Diego County, CAL Fire Souther...</td>\n",
       "      <td>32.717420</td>\n",
       "      <td>-117.162773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>$150,601</td>\n",
       "      <td>(San Jose, Santa Clara County, CAL Fire Northe...</td>\n",
       "      <td>37.336166</td>\n",
       "      <td>-121.890591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>$167,663</td>\n",
       "      <td>(San Francisco, CAL Fire Northern Region, Cali...</td>\n",
       "      <td>37.779026</td>\n",
       "      <td>-122.419906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fresno</td>\n",
       "      <td>$73,396</td>\n",
       "      <td>(Fresno, Fresno County, CAL Fire Southern Regi...</td>\n",
       "      <td>36.739442</td>\n",
       "      <td>-119.784831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>$87,213</td>\n",
       "      <td>(Sacramento, Sacramento County, CAL Fire North...</td>\n",
       "      <td>38.581061</td>\n",
       "      <td>-121.493895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Long Beach</td>\n",
       "      <td>$89,912</td>\n",
       "      <td>(Long Beach, Los Angeles County, CAL Fire Cont...</td>\n",
       "      <td>33.769016</td>\n",
       "      <td>-118.191604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oakland</td>\n",
       "      <td>$116,585</td>\n",
       "      <td>(Oakland, Alameda County, CAL Fire Northern Re...</td>\n",
       "      <td>37.804456</td>\n",
       "      <td>-122.271356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bakersfield</td>\n",
       "      <td>$84,592</td>\n",
       "      <td>(Bakersfield, Kern County, CAL Fire Southern R...</td>\n",
       "      <td>35.373871</td>\n",
       "      <td>-119.019464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anaheim</td>\n",
       "      <td>$97,136</td>\n",
       "      <td>(Anaheim, Orange County, CAL Fire Contract Cou...</td>\n",
       "      <td>33.834752</td>\n",
       "      <td>-117.911732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Santa Ana</td>\n",
       "      <td>$88,829</td>\n",
       "      <td>(Santa Ana, Orange County, CAL Fire Southern R...</td>\n",
       "      <td>33.749495</td>\n",
       "      <td>-117.873221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Riverside</td>\n",
       "      <td>$90,520</td>\n",
       "      <td>(Riverside, Riverside County, California, Unit...</td>\n",
       "      <td>33.953355</td>\n",
       "      <td>-117.396162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Stockton</td>\n",
       "      <td>$78,712</td>\n",
       "      <td>(Stockton, San Joaquin County, CAL Fire Southe...</td>\n",
       "      <td>37.957702</td>\n",
       "      <td>-121.290780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chula Vista</td>\n",
       "      <td>$105,155</td>\n",
       "      <td>(Chula Vista, San Diego County, California, Un...</td>\n",
       "      <td>32.640054</td>\n",
       "      <td>-117.084196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Irvine</td>\n",
       "      <td>$140,764</td>\n",
       "      <td>(Irvine, Orange County, CAL Fire Southern Regi...</td>\n",
       "      <td>33.685697</td>\n",
       "      <td>-117.825982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fremont</td>\n",
       "      <td>$170,083</td>\n",
       "      <td>(Fremont, Alameda County, CAL Fire Northern Re...</td>\n",
       "      <td>37.548270</td>\n",
       "      <td>-121.988571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>San Bernardino</td>\n",
       "      <td>$64,929</td>\n",
       "      <td>(San Bernardino County, CAL Fire Southern Regi...</td>\n",
       "      <td>34.825302</td>\n",
       "      <td>-116.083314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Modesto</td>\n",
       "      <td>$81,841</td>\n",
       "      <td>(Modesto, Stanislaus County, CAL Fire Southern...</td>\n",
       "      <td>37.639097</td>\n",
       "      <td>-120.996878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fontana</td>\n",
       "      <td>$93,383</td>\n",
       "      <td>(Fontana, San Bernardino County, CAL Fire Sout...</td>\n",
       "      <td>34.092233</td>\n",
       "      <td>-117.435048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Oxnard</td>\n",
       "      <td>$91,636</td>\n",
       "      <td>(Oxnard, Ventura County, CAL Fire Contract Cou...</td>\n",
       "      <td>34.197631</td>\n",
       "      <td>-119.180382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              City Average Household Income  \\\n",
       "0      Los Angeles                 $101,006   \n",
       "1        San Diego                 $113,681   \n",
       "2         San Jose                 $150,601   \n",
       "3    San Francisco                 $167,663   \n",
       "4           Fresno                  $73,396   \n",
       "5       Sacramento                  $87,213   \n",
       "6       Long Beach                  $89,912   \n",
       "7          Oakland                 $116,585   \n",
       "8      Bakersfield                  $84,592   \n",
       "9          Anaheim                  $97,136   \n",
       "10       Santa Ana                  $88,829   \n",
       "11       Riverside                  $90,520   \n",
       "12        Stockton                  $78,712   \n",
       "13     Chula Vista                 $105,155   \n",
       "14          Irvine                 $140,764   \n",
       "15         Fremont                 $170,083   \n",
       "16  San Bernardino                  $64,929   \n",
       "17         Modesto                  $81,841   \n",
       "18         Fontana                  $93,383   \n",
       "19          Oxnard                  $91,636   \n",
       "\n",
       "                                             location   latitude   longitude  \n",
       "0   (Los Angeles, Los Angeles County, CAL Fire Con...  34.053691 -118.242766  \n",
       "1   (San Diego, San Diego County, CAL Fire Souther...  32.717420 -117.162773  \n",
       "2   (San Jose, Santa Clara County, CAL Fire Northe...  37.336166 -121.890591  \n",
       "3   (San Francisco, CAL Fire Northern Region, Cali...  37.779026 -122.419906  \n",
       "4   (Fresno, Fresno County, CAL Fire Southern Regi...  36.739442 -119.784831  \n",
       "5   (Sacramento, Sacramento County, CAL Fire North...  38.581061 -121.493895  \n",
       "6   (Long Beach, Los Angeles County, CAL Fire Cont...  33.769016 -118.191604  \n",
       "7   (Oakland, Alameda County, CAL Fire Northern Re...  37.804456 -122.271356  \n",
       "8   (Bakersfield, Kern County, CAL Fire Southern R...  35.373871 -119.019464  \n",
       "9   (Anaheim, Orange County, CAL Fire Contract Cou...  33.834752 -117.911732  \n",
       "10  (Santa Ana, Orange County, CAL Fire Southern R...  33.749495 -117.873221  \n",
       "11  (Riverside, Riverside County, California, Unit...  33.953355 -117.396162  \n",
       "12  (Stockton, San Joaquin County, CAL Fire Southe...  37.957702 -121.290780  \n",
       "13  (Chula Vista, San Diego County, California, Un...  32.640054 -117.084196  \n",
       "14  (Irvine, Orange County, CAL Fire Southern Regi...  33.685697 -117.825982  \n",
       "15  (Fremont, Alameda County, CAL Fire Northern Re...  37.548270 -121.988571  \n",
       "16  (San Bernardino County, CAL Fire Southern Regi...  34.825302 -116.083314  \n",
       "17  (Modesto, Stanislaus County, CAL Fire Southern...  37.639097 -120.996878  \n",
       "18  (Fontana, San Bernardino County, CAL Fire Sout...  34.092233 -117.435048  \n",
       "19  (Oxnard, Ventura County, CAL Fire Contract Cou...  34.197631 -119.180382  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert value like $101,006' to 101006\n",
    "df_cities[\"Average Household Income\"] = df_cities[\"Average Household Income\"].apply(lambda x: int(x.replace(\"$\", \"\").replace(\",\", \"\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Average Household Income</th>\n",
       "      <th>location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>101006</td>\n",
       "      <td>(Los Angeles, Los Angeles County, CAL Fire Con...</td>\n",
       "      <td>34.053691</td>\n",
       "      <td>-118.242766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>113681</td>\n",
       "      <td>(San Diego, San Diego County, CAL Fire Souther...</td>\n",
       "      <td>32.717420</td>\n",
       "      <td>-117.162773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>150601</td>\n",
       "      <td>(San Jose, Santa Clara County, CAL Fire Northe...</td>\n",
       "      <td>37.336166</td>\n",
       "      <td>-121.890591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>167663</td>\n",
       "      <td>(San Francisco, CAL Fire Northern Region, Cali...</td>\n",
       "      <td>37.779026</td>\n",
       "      <td>-122.419906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fresno</td>\n",
       "      <td>73396</td>\n",
       "      <td>(Fresno, Fresno County, CAL Fire Southern Regi...</td>\n",
       "      <td>36.739442</td>\n",
       "      <td>-119.784831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City  Average Household Income  \\\n",
       "0    Los Angeles                    101006   \n",
       "1      San Diego                    113681   \n",
       "2       San Jose                    150601   \n",
       "3  San Francisco                    167663   \n",
       "4         Fresno                     73396   \n",
       "\n",
       "                                            location   latitude   longitude  \n",
       "0  (Los Angeles, Los Angeles County, CAL Fire Con...  34.053691 -118.242766  \n",
       "1  (San Diego, San Diego County, CAL Fire Souther...  32.717420 -117.162773  \n",
       "2  (San Jose, Santa Clara County, CAL Fire Northe...  37.336166 -121.890591  \n",
       "3  (San Francisco, CAL Fire Northern Region, Cali...  37.779026 -122.419906  \n",
       "4  (Fresno, Fresno County, CAL Fire Southern Regi...  36.739442 -119.784831  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df_cities to a torch tensor\n",
    "cities_tensor = torch.tensor(df_cities[[\"Average Household Income\", \"latitude\", \"longitude\"]].values).float()\n",
    "# Reshape\n",
    "cities_tensor = cities_tensor.reshape(cities_tensor.shape[0], 1, cities_tensor.shape[1])\n",
    "\n",
    "# preporcess the data\n",
    "#cities_tensor_processed = preprocess_input(cities_tensor, target_tensor, [], preprocess_transform='power')\n",
    "#cities_tensor_processed = cities_tensor\n",
    "# Use a standard scaler\n",
    "scaler = StandardScaler()\n",
    "cities_tensor_processed = torch.tensor(scaler.fit_transform(cities_tensor.reshape(-1, cities_tensor.shape[-1])).reshape(cities_tensor.shape))\n",
    "# convert to float\n",
    "cities_tensor_processed = cities_tensor_processed.float()\n",
    "\n",
    "# Pad last dimension with 0 to 100\n",
    "#TODO: think, do I need to do this or can I just put the vector in the attention?\n",
    "cities_tensor_processed = torch.nn.functional.pad(cities_tensor_processed, (0, 100-cities_tensor.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to GPU\n",
    "cities_tensor_processed = cities_tensor_processed.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multihead attention\n",
    "from torch.nn import MultiheadAttention\n",
    "n = 512\n",
    "attention = MultiheadAttention(embed_dim=n, num_heads=1, dropout=0.0, device=device)\n",
    "W_q = torch.rand(n, n).to(device)\n",
    "W_k = torch.rand(n, n).to(device)\n",
    "W_v = torch.rand(n, n).to(device)\n",
    "W_q.requires_grad = True\n",
    "W_k.requires_grad = True\n",
    "W_v.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000\n",
    "val_size = 2000\n",
    "test_size = 2000\n",
    "\n",
    "assert train_size + val_size + test_size == len(california_tensor_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suffle the \"Average Household Income\" column\n",
    "cities_tensor_processed_random = cities_tensor_processed[torch.randperm(cities_tensor_processed.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_mask None\n",
      "tensor(0.4882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "0.7615\n",
      "src_mask None\n",
      "tensor(0.4905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4556, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4360, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "0.804\n",
      "src_mask None\n",
      "tensor(0.4248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4140, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "0.8145\n",
      "src_mask None\n",
      "tensor(0.4094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.4005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "0.815\n",
      "src_mask None\n",
      "tensor(0.3970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "0.816\n",
      "src_mask None\n",
      "tensor(0.3895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "0.816\n",
      "src_mask None\n",
      "tensor(0.3825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "0.814\n",
      "src_mask None\n",
      "tensor(0.3794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "0.817\n",
      "src_mask None\n",
      "tensor(0.3761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "0.8205\n",
      "src_mask None\n",
      "tensor(0.3744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "0.822\n",
      "src_mask None\n",
      "tensor(0.3737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "src_mask None\n",
      "tensor(0.3729, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# optimize the attention matrix W_q, W_k, W_v\n",
    "#TODO: check if we train on test\n",
    "from torch import optim\n",
    "optimizer = optim.Adam([W_q, W_k, W_v], lr=0.01)\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    input = model.model[2].encoder(california_without_income_tensor_processed)\n",
    "    input2 = model.model[2].encoder(cities_tensor_processed)\n",
    "    Q = torch.matmul(input, W_q)\n",
    "    K = torch.matmul(input2, W_k)\n",
    "    V = torch.matmul(input2, W_v)\n",
    "    full_input = input + attention(Q, K, V)[0]\n",
    "    y_pred = module((full_input, target_tensor), single_eval_pos=train_size, x_already_encoded=True).squeeze()\n",
    "    loss = torch.nn.functional.cross_entropy(y_pred[:val_size], target_tensor[-len(y_pred):-len(y_pred) + val_size].squeeze().long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    if i % 10 == 0:\n",
    "        y_pred = torch.argmax(y_pred, dim=-1).reshape(-1)\n",
    "        print(accuracy_score(target_tensor[-len(y_pred) + val_size:].cpu(), y_pred[val_size:].cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: GPU and correct scoring of baselinees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tab_pfn2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21dbb7094b1385f0bae0b91ae49063169e8dea4181459eda714e1f1fb7500475"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
