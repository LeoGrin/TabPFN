{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' from '/home/parietal/lgrinszt/.local/miniconda3/envs/tab_pfn2/lib/python3.9/site-packages/wandb/__init__.py'>\n",
      "Using cpu device\n",
      "Batch size: 1\n",
      "Using distributed training: False\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    }
   ],
   "source": [
    "from tabpfn.scripts.transformer_prediction_interface import TabPFNClassifier\n",
    "from tabpfn.scripts.transformer_prediction_interface import transformer_predict\n",
    "\n",
    "model = TabPFNClassifier()\n",
    "\n",
    "# import train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 1, 512])\n",
      "torch.Size([200, 1, 512])\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([200, 1, 512])\n",
      "torch.Size([200, 1, 512])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([200, 1, 512])\n",
      "torch.Size([200, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "# Feed an input to the model and check that the differentation works\n",
    "# Create a random input\n",
    "input = torch.rand(200, 1, 100)\n",
    "# Create a random binary target\n",
    "target = torch.randint(0, 2, (200, 1)).float()\n",
    "\n",
    "# Differentiate the input\n",
    "input.requires_grad = True\n",
    "\n",
    "# Feed the input to the model\n",
    "#output = model.fit(input, target) #Doesn't work\n",
    "module = model.model[2]\n",
    "module.efficient_eval_masking = True\n",
    "module.full_attention = False\n",
    "single_eval_pos = 10\n",
    "output = module((input, target), single_eval_pos=single_eval_pos) #Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fake datasets\n",
    "# Create a first dataset with columns A, B\n",
    "dataset1 = torch.rand(1000, 1, 100)\n",
    "# Create a second dataset with columns C, D\n",
    "dataset2 = torch.rand(1000, 1, 100)\n",
    "\n",
    "# Make column C equal to column A * 2 + noise\n",
    "dataset2[:, 0] = dataset1[:, :, 0] * 2 #+ torch.rand(1000) * 0.1\n",
    "\n",
    "# Create y as D + noise\n",
    "y = dataset2[:, :, 1] #+ torch.rand(1000) * 0.1\n",
    "\n",
    "dataset2.requires_grad = True\n",
    "dataset1.requires_grad = True\n",
    "\n",
    "# Make it a classification problem\n",
    "y = (y > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' from '/home/parietal/lgrinszt/.local/miniconda3/envs/tab_pfn2/lib/python3.9/site-packages/wandb/__init__.py'>\n",
      "Using cpu device\n",
      "Batch size: 1\n",
      "Using distributed training: False\n",
      "Using a Transformer with 25.82 M parameters\n",
      "interface\n",
      "torch.Size([1000, 1, 100])\n",
      "torch.Size([1000, 1])\n",
      "800\n",
      "torch.Size([1000, 3, 512])\n",
      "torch.Size([800, 3, 512])\n",
      "torch.Size([800, 3, 512])\n",
      "torch.Size([800, 3, 512])\n",
      "torch.Size([1000, 3, 512])\n",
      "torch.Size([1000, 3, 512])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parietal/lgrinszt/.local/miniconda3/envs/tab_pfn2/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3, 512])\n",
      "torch.Size([1000, 3, 10])\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.71\n"
     ]
    }
   ],
   "source": [
    "# Try TabPFN on dataset1\n",
    "model = TabPFNClassifier()\n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset2, y, test_size=0.2, random_state=42)\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "# Check the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style prior: True\n",
      "{'recompute_attn': True}\n",
      "<module 'wandb' from '/home/parietal/lgrinszt/.local/miniconda3/envs/tab_pfn2/lib/python3.9/site-packages/wandb/__init__.py'>\n",
      "Using cpu device\n",
      "Batch size: 1\n",
      "Using distributed training: False\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabpfn.transformer_2 import TransformerModel2\n",
    "from tabpfn.scripts.transformer_prediction_interface import TabPFNClassifier\n",
    "\n",
    "model = TabPFNClassifier()\n",
    "module = model.model[2]\n",
    "config = model.c\n",
    "\n",
    "model_torch = TransformerModel2(nhead=config[\"nhead\"], nlayers=config[\"nlayers\"],\n",
    "                                encoder=module.encoder, y_encoder=module.y_encoder,\n",
    "                                n_out=module.n_out, ninp=module.ninp, nhid=module.nhid,\n",
    "                                efficient_eval_masking=module.efficient_eval_masking,\n",
    "                                full_attention=module.full_attention)\n",
    "# Transfer the weights\n",
    "weights_to_transfer = model.model[2].state_dict()\n",
    "weights_to_transfer.pop(\"criterion.weight\")\n",
    "model_torch.load_state_dict(weights_to_transfer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5668, 0.3454, 0.7760,  ..., 0.5050, 0.1498, 0.7433]],\n",
       "\n",
       "        [[0.4660, 0.5265, 0.3188,  ..., 0.1435, 0.0943, 0.2766]],\n",
       "\n",
       "        [[0.9613, 0.8483, 0.9688,  ..., 0.5763, 0.0273, 0.4668]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3341, 0.6840, 0.5179,  ..., 0.3008, 0.4581, 0.4205]],\n",
       "\n",
       "        [[0.3116, 0.3167, 0.6324,  ..., 0.7637, 0.0793, 0.2207]],\n",
       "\n",
       "        [[0.3328, 0.2110, 0.3774,  ..., 0.6141, 0.2846, 0.4213]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 512])\n",
      "torch.Size([1000, 1, 512])\n",
      "torch.Size([200, 1, 512])\n",
      "torch.Size([200, 1, 512])\n",
      "torch.Size([1000, 1, 512])\n",
      "torch.Size([1000, 1, 512])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1000, 1, 512])\n",
      "torch.Size([1000, 1, 10])\n",
      "tensor([[[  0.3168,  11.3697,  -8.4459,  ..., -14.3448, -10.8779,  -9.1673]],\n",
      "\n",
      "        [[ 10.9316,   0.3576,  -5.8419,  ..., -14.1164, -13.4658, -12.1414]],\n",
      "\n",
      "        [[  2.8302,  11.0658,  -8.6245,  ..., -13.8329, -12.5138, -11.6858]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  2.3440,  11.5596,  -8.9687,  ..., -14.3094, -12.2946, -11.2831]],\n",
      "\n",
      "        [[  2.7327,  11.2391,  -8.7390,  ..., -13.9931, -12.4805, -11.5873]],\n",
      "\n",
      "        [[  2.3710,  11.5477,  -8.9633,  ..., -14.2959, -12.3061, -11.2988]]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "torch.Size([1000, 1, 512])\n",
      "torch.Size([1000, 1, 512])\n",
      "torch.Size([200, 1, 512])\n",
      "torch.Size([200, 1, 512])\n",
      "torch.Size([1000, 1, 512])\n",
      "torch.Size([1000, 1, 512])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1000, 1, 512])\n",
      "torch.Size([1000, 1, 10])\n",
      "tensor([1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        0, 0, 1, 1, 0, 1, 1, 1])\n",
      "torch.Size([800])\n",
      "0.9975\n"
     ]
    }
   ],
   "source": [
    "#y_pred = transformer_predict(model.model[2], dataset1, y, single_eval_pos=600, eval_position=600,\n",
    "#                                          preprocess_transform=\"none\")\n",
    "#print(model.model[2]((dataset2, y)))\n",
    "print(model.model[2]((dataset2, y), single_eval_pos=200))\n",
    "y_pred = torch.argmax(model.model[2]((dataset2, y), single_eval_pos=200), dim=-1).reshape(-1)\n",
    "print(y_pred)\n",
    "print(y_pred.shape)\n",
    "# Check the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y[-len(y_pred):], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multihead attention\n",
    "from torch.nn import MultiheadAttention\n",
    "attention = MultiheadAttention(embed_dim=100, num_heads=1, dropout=0.0)\n",
    "W_q = torch.rand(100, 100)\n",
    "W_k = torch.rand(100, 100)\n",
    "W_v = torch.rand(100, 100)\n",
    "W_q.requires_grad = True\n",
    "W_k.requires_grad = True\n",
    "W_v.requires_grad = True\n",
    "\n",
    "Q = torch.matmul(dataset1, W_q)\n",
    "K = torch.matmul(dataset2, W_k)\n",
    "V = torch.matmul(dataset2, W_v)\n",
    "\n",
    "# Transform dataset1 by applying the attention to dataset2\n",
    "dataset1 = attention(Q, K, V)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 100])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 512])\n",
      "torch.Size([1000, 1, 512])\n",
      "torch.Size([200, 1, 512])\n",
      "torch.Size([200, 1, 512])\n",
      "torch.Size([1000, 1, 512])\n",
      "torch.Size([1000, 1, 512])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1000, 1, 512])\n",
      "torch.Size([1000, 1, 10])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "torch.Size([800])\n",
      "0.7625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = torch.argmax(model.model[2]((dataset1, y), single_eval_pos=200), dim=-1).reshape(-1)\n",
    "print(y_pred)\n",
    "print(y_pred.shape)\n",
    "# Check the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y[-len(y_pred):], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tab_pfn2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21dbb7094b1385f0bae0b91ae49063169e8dea4181459eda714e1f1fb7500475"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
